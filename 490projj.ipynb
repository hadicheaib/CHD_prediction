{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5CydYn_IMK92",
   "metadata": {
    "id": "5CydYn_IMK92"
   },
   "source": [
    "## Detailed pipeline overview — what happens and why\n",
    "\n",
    "This notebook follows a **full ML pipeline** for CHD risk prediction. Here is the big picture:\n",
    "\n",
    "1. **Load & inspect the data**  \n",
    "   - We read `framingham.csv` into a DataFrame and print its shape and first rows.  \n",
    "   - **Why:** sanity‑check that the file is correct and see what features we have (age, blood pressure, cholesterol, etc.).\n",
    "\n",
    "2. **Basic preprocessing**  \n",
    "   - Drop completely empty rows/columns.  \n",
    "   - Convert object‑type columns to numeric where possible.  \n",
    "   - Handle missing values (median imputation for numeric columns; finally drop any rows that are still problematic).  \n",
    "   - **Why:** most ML models require clean numeric matrices with no NaNs. This step ensures the dataset is usable and stable for all later steps.\n",
    "\n",
    "3. **Feature engineering**  \n",
    "   - Create clinically meaningful features like **pulse pressure** (sysBP − diaBP), **mean arterial pressure (MAP)**, and an interaction **age × systolic BP**.  \n",
    "   - Define `X` (all predictor columns) and `y` (the 10‑year CHD outcome).  \n",
    "   - **Why:** engineered features can capture relationships (e.g., vascular stiffness) that raw columns alone do not express cleanly, improving model power.\n",
    "\n",
    "4. **mRMR feature selection (supervised)**  \n",
    "   - Use **mutual information** with the target to measure how informative each feature is.  \n",
    "   - Penalize picking features that are highly correlated with already‑selected ones (to reduce redundancy).  \n",
    "   - Greedily select ~10 features that are **highly relevant but not redundant**.  \n",
    "   - **Why:** a small, well‑chosen subset can improve generalization, reduce noise, and make the model easier to interpret.\n",
    "\n",
    "5. **PCA feature set (unsupervised dimensionality reduction)**  \n",
    "   - Standardize features, then apply **PCA** to get 12 principal components.  \n",
    "   - These components are linear combinations of original features and are mutually uncorrelated.  \n",
    "   - **Why:** PCA compresses information into a lower‑dimensional space and removes multicollinearity, which can help some models and make optimization easier.\n",
    "\n",
    "6. **Class balancing via manual oversampling**  \n",
    "   - The outcome is imbalanced (few CHD=1 vs. many CHD=0).  \n",
    "   - We oversample the minority class by duplicating its rows until both classes have equal counts.  \n",
    "   - **Why:** this helps the model pay attention to the rare positive class rather than \"cheating\" by always predicting the majority class.\n",
    "\n",
    "7. **Train & compare multiple model configurations on each feature set**  \n",
    "   - Use 10‑fold **StratifiedKFold** cross‑validation to keep class ratios similar in each fold.  \n",
    "   - Evaluate multiple models with different complexity levels: ExtraTrees, RandomForest, GradientBoosting, DecisionTree, LogisticRegression, SVC, MLP, and optionally XGBoost.\n",
    "   - Each model is tested in **simple, medium, and complex** configurations to explore the bias-variance tradeoff.\n",
    "   - Compute metrics: accuracy, precision, recall, F1, ROC‑AUC, plus model size, training time, and prediction latency.  \n",
    "   - **Why:** instead of assuming one model/feature set is best, we **empirically compare** them and see which combination works best for both performance and deployment constraints.\n",
    "\n",
    "8. **Hyperparameter tuning for ExtraTrees on PCA features**  \n",
    "   - Once we identify a strong combination (ExtraTrees + PCA), we tune its hyperparameters using **RandomizedSearchCV** with ROC‑AUC scoring.  \n",
    "   - **Why:** tuning lets the model find a better bias–variance trade‑off and typically improves performance beyond default settings.\n",
    "\n",
    "9. **Final evaluation on a held‑out test split**  \n",
    "   - Split the (balanced PCA) data into train and test once.  \n",
    "   - Train on the train set, evaluate only on the test set, and report all metrics.  \n",
    "   - **Why:** this is our **honest, final estimate** of performance on unseen patients.\n",
    "\n",
    "10. **Explainability: SHAP (global+local) and LIME (local)**  \n",
    "   - **SHAP**: uses Shapley values to measure each feature's contribution to predictions across the dataset (global) and for specific individuals (local).  \n",
    "   - **LIME**: approximates the model locally around a single point with a simple surrogate to explain one prediction.  \n",
    "   - **Why:** in healthcare, we must understand *why* the model flags a patient as high‑risk. XAI methods provide transparency and help detect spurious behavior.\n",
    "\n",
    "11. **Save the final model**  \n",
    "   - Store the tuned ExtraTrees model with joblib.  \n",
    "   - **Why:** so you can reuse it later (in another notebook, an API, or a simple app) without retraining every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3432250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries (Google Colab friendly)\n",
    "# Run this once at the start of your Colab session.\n",
    "!pip install -q numpy pandas scikit-learn matplotlib seaborn xgboost catboost shap lime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e4c6f1",
   "metadata": {
    "id": "b4e4c6f1"
   },
   "source": [
    "# Framingham Heart Disease Risk Pipeline\n",
    "\n",
    "This notebook builds and explains a **10‑year coronary heart disease (CHD) risk classifier** using the Framingham Heart Study dataset.  \n",
    "It run smoothly on **Google Colab** and is heavily commented so you can understand *what* happens at each step and *why* it is done that way.\n",
    "\n",
    "### How to use this notebook in Colab\n",
    "\n",
    "1. **Run the install cell** right below this (it uses `!pip` to install all needed libraries).\n",
    "2. **Run the data loading cell**:  \n",
    "   - If `framingham.csv` is already in the working directory, it will be loaded directly.  \n",
    "   - If not, Colab will ask you to **upload** the CSV file manually.\n",
    "3. Then run the remaining cells **in order**:\n",
    "   - Data cleaning & feature engineering  \n",
    "   - Feature selection with **mRMR** and dimensionality reduction with **PCA**  \n",
    "   - Class balancing (oversampling)  \n",
    "   - Training and comparing several models  \n",
    "   - Hyperparameter tuning for the best model  \n",
    "   - **Explainable AI (XAI)** with SHAP (global & local) and LIME (local)  \n",
    "   - Saving the final trained model for reuse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6e91e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy already installed.\n",
      "pandas already installed.\n",
      "scikit-learn already installed.\n",
      "matplotlib already installed.\n",
      "seaborn already installed.\n",
      "xgboost already installed.\n",
      "catboost already installed.\n",
      "shap already installed.\n",
      "lime already installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hadi\\Desktop\\49000\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def ensure_package(pkg, import_name=None):\n",
    "    import_name = import_name or pkg\n",
    "    try:\n",
    "        importlib.import_module(import_name)\n",
    "        print(f\"{pkg} already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {pkg}...\")\n",
    "        # Do not fail the notebook if installation fails (e.g. offline environment)\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", pkg], check=False)\n",
    "\n",
    "packages = [\n",
    "    (\"numpy\", \"numpy\"),\n",
    "    (\"pandas\", \"pandas\"),\n",
    "    (\"scikit-learn\", \"sklearn\"),\n",
    "    (\"matplotlib\", \"matplotlib\"),\n",
    "    (\"seaborn\", \"seaborn\"),\n",
    "    (\"xgboost\", \"xgboost\"),\n",
    "    (\"catboost\", \"catboost\"),\n",
    "    (\"shap\", \"shap\"),\n",
    "    (\"lime\", \"lime\"),\n",
    "]\n",
    "\n",
    "for pkg, import_name in packages:\n",
    "    ensure_package(pkg, import_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbac4f5",
   "metadata": {
    "id": "4fbac4f5",
    "papermill": {
     "duration": 0.004676,
     "end_time": "2025-10-24T15:56:38.034399",
     "exception": false,
     "start_time": "2025-10-24T15:56:38.029723",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    " Dataset path (kaggle): https://www.kaggle.com/datasets/aasheesh200/framingham-heart-study-dataset?select=framingham.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5287154f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T15:56:38.045001Z",
     "iopub.status.busy": "2025-10-24T15:56:38.044666Z",
     "iopub.status.idle": "2025-10-24T15:56:39.904291Z",
     "shell.execute_reply": "2025-10-24T15:56:39.903439Z"
    },
    "id": "5287154f",
    "papermill": {
     "duration": 1.866348,
     "end_time": "2025-10-24T15:56:39.905825",
     "exception": false,
     "start_time": "2025-10-24T15:56:38.039477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaa56fe",
   "metadata": {
    "id": "bfaa56fe",
    "papermill": {
     "duration": 0.004269,
     "end_time": "2025-10-24T15:56:39.914896",
     "exception": false,
     "start_time": "2025-10-24T15:56:39.910627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad867b8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T15:56:39.925609Z",
     "iopub.status.busy": "2025-10-24T15:56:39.924930Z",
     "iopub.status.idle": "2025-10-24T15:56:42.273565Z",
     "shell.execute_reply": "2025-10-24T15:56:42.272917Z"
    },
    "id": "ad867b8c",
    "papermill": {
     "duration": 2.355368,
     "end_time": "2025-10-24T15:56:42.275078",
     "exception": false,
     "start_time": "2025-10-24T15:56:39.919710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9c0bae",
   "metadata": {
    "id": "aa9c0bae",
    "papermill": {
     "duration": 0.004317,
     "end_time": "2025-10-24T15:56:42.284659",
     "exception": false,
     "start_time": "2025-10-24T15:56:42.280342",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a356a92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T15:56:42.294748Z",
     "iopub.status.busy": "2025-10-24T15:56:42.294254Z",
     "iopub.status.idle": "2025-10-24T15:56:42.906230Z",
     "shell.execute_reply": "2025-10-24T15:56:42.905553Z"
    },
    "id": "8a356a92",
    "papermill": {
     "duration": 0.618337,
     "end_time": "2025-10-24T15:56:42.907616",
     "exception": false,
     "start_time": "2025-10-24T15:56:42.289279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, cross_validate, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d348a281",
   "metadata": {
    "id": "d348a281",
    "papermill": {
     "duration": 0.0043,
     "end_time": "2025-10-24T15:56:42.916579",
     "exception": false,
     "start_time": "2025-10-24T15:56:42.912279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ada1d74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T15:56:42.926434Z",
     "iopub.status.busy": "2025-10-24T15:56:42.926171Z",
     "iopub.status.idle": "2025-10-24T15:56:44.038643Z",
     "shell.execute_reply": "2025-10-24T15:56:44.037803Z"
    },
    "id": "3ada1d74",
    "papermill": {
     "duration": 1.119029,
     "end_time": "2025-10-24T15:56:44.040062",
     "exception": false,
     "start_time": "2025-10-24T15:56:42.921033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Try to import xgboost and catboost if available\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a818f55",
   "metadata": {
    "id": "4a818f55",
    "papermill": {
     "duration": 0.00467,
     "end_time": "2025-10-24T15:56:44.049466",
     "exception": false,
     "start_time": "2025-10-24T15:56:44.044796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbdacacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "from lime.lime_tabular import LimeTabularExplainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c2faaf",
   "metadata": {
    "id": "75c2faaf",
    "papermill": {
     "duration": 0.004543,
     "end_time": "2025-10-24T15:56:53.734747",
     "exception": false,
     "start_time": "2025-10-24T15:56:53.730204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# 1. Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ab01f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded to: C:\\Users\\hadi\\.cache\\kagglehub\\datasets\\aasheesh200\\framingham-heart-study-dataset\\versions\\1\n",
      "framingham.csv already exists in: c:\\Users\\hadi\\Desktop\\49000\\framingham.csv\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Download dataset from Kaggle\n",
    "downloaded_path = kagglehub.dataset_download(\"aasheesh200/framingham-heart-study-dataset\")\n",
    "print(f\"Dataset downloaded to: {downloaded_path}\")\n",
    "\n",
    "# Define the target directory (current working directory)\n",
    "target_dir = Path.cwd()\n",
    "target_csv = target_dir / \"framingham.csv\"\n",
    "\n",
    "# Find the CSV in the downloaded path\n",
    "source_csv = Path(downloaded_path) / \"framingham.csv\"\n",
    "\n",
    "# Copy to current directory if not already there\n",
    "if source_csv.exists() and not target_csv.exists():\n",
    "    shutil.copy2(source_csv, target_csv)\n",
    "    print(f\"Copied framingham.csv to: {target_csv}\")\n",
    "elif target_csv.exists():\n",
    "    print(f\"framingham.csv already exists in: {target_csv}\")\n",
    "else:\n",
    "    print(f\"Warning: Could not find framingham.csv in {downloaded_path}\")\n",
    "    \n",
    "data_path = target_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bda172c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path: c:\\Users\\hadi\\Desktop\\49000\\framingham.csv\n",
      "File exists: True\n"
     ]
    }
   ],
   "source": [
    "# Verify the path\n",
    "print(f\"Data path: {data_path}\")\n",
    "print(f\"File exists: {data_path.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a789f038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data file: c:\\Users\\hadi\\Desktop\\49000\\framingham.csv\n",
      "Loaded: (4238, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "print(f\"Using data file: {data_path}\")\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"Loaded:\", df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82918651",
   "metadata": {
    "id": "82918651",
    "papermill": {
     "duration": 0.00427,
     "end_time": "2025-10-24T15:56:53.807480",
     "exception": false,
     "start_time": "2025-10-24T15:56:53.803210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# 2. Basic preprocessing\n",
    "\n",
    "Drops columns and rows that are completely empty.\n",
    "\n",
    "\n",
    "\n",
    "Prints how many missing values each column has.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce3ee28b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-24T15:56:53.817132Z",
     "iopub.status.busy": "2025-10-24T15:56:53.816861Z",
     "iopub.status.idle": "2025-10-24T15:56:53.834280Z",
     "shell.execute_reply": "2025-10-24T15:56:53.833351Z"
    },
    "id": "ce3ee28b",
    "outputId": "339a1ece-d00e-4711-b468-e3539042470e",
    "papermill": {
     "duration": 0.023873,
     "end_time": "2025-10-24T15:56:53.835589",
     "exception": false,
     "start_time": "2025-10-24T15:56:53.811716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (4238, 16)\n",
      "\n",
      "Initial dtypes:\n",
      " male                 int64\n",
      "age                  int64\n",
      "education          float64\n",
      "currentSmoker        int64\n",
      "cigsPerDay         float64\n",
      "BPMeds             float64\n",
      "prevalentStroke      int64\n",
      "prevalentHyp         int64\n",
      "diabetes             int64\n",
      "totChol            float64\n",
      "sysBP              float64\n",
      "diaBP              float64\n",
      "BMI                float64\n",
      "heartRate          float64\n",
      "glucose            float64\n",
      "TenYearCHD           int64\n",
      "dtype: object\n",
      "\n",
      "Initial missing values per column:\n",
      " male                 0\n",
      "age                  0\n",
      "education          105\n",
      "currentSmoker        0\n",
      "cigsPerDay          29\n",
      "BPMeds              53\n",
      "prevalentStroke      0\n",
      "prevalentHyp         0\n",
      "diabetes             0\n",
      "totChol             50\n",
      "sysBP                0\n",
      "diaBP                0\n",
      "BMI                 19\n",
      "heartRate            1\n",
      "glucose            388\n",
      "TenYearCHD           0\n",
      "dtype: int64\n",
      "\n",
      "After dropping completely empty rows/cols, shape: (4238, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial shape:\", df.shape)\n",
    "print(\"\\nInitial dtypes:\\n\", df.dtypes)\n",
    "print(\"\\nInitial missing values per column:\\n\", df.isna().sum())\n",
    "\n",
    "# Drop columns where every value is NaN\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Drop rows where every value is NaN\n",
    "df = df.dropna(axis=0, how='all')\n",
    "\n",
    "print(\"\\nAfter dropping completely empty rows/cols, shape:\", df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3edM5W30WgTF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3edM5W30WgTF",
    "outputId": "a24862a0-aa93-4bc3-ae16-d8199123db0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column after normalizing fake NAs:\n",
      " male                 0\n",
      "age                  0\n",
      "education          105\n",
      "currentSmoker        0\n",
      "cigsPerDay          29\n",
      "BPMeds              53\n",
      "prevalentStroke      0\n",
      "prevalentHyp         0\n",
      "diabetes             0\n",
      "totChol             50\n",
      "sysBP                0\n",
      "diaBP                0\n",
      "BMI                 19\n",
      "heartRate            1\n",
      "glucose            388\n",
      "TenYearCHD           0\n",
      "dtype: int64\n",
      "Dropped 0 rows with missing TenYearCHD.\n",
      "\n",
      "Numeric columns detected (for imputation/outlier handling):\n",
      " ['male', 'age', 'education', 'currentSmoker', 'cigsPerDay', 'BPMeds', 'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose', 'TenYearCHD']\n",
      "\n",
      "Numeric missing fraction (pre‑imputation):\n",
      " glucose            0.091553\n",
      "education          0.024776\n",
      "BPMeds             0.012506\n",
      "totChol            0.011798\n",
      "cigsPerDay         0.006843\n",
      "BMI                0.004483\n",
      "heartRate          0.000236\n",
      "male               0.000000\n",
      "prevalentHyp       0.000000\n",
      "prevalentStroke    0.000000\n",
      "age                0.000000\n",
      "currentSmoker      0.000000\n",
      "diaBP              0.000000\n",
      "sysBP              0.000000\n",
      "diabetes           0.000000\n",
      "TenYearCHD         0.000000\n",
      "dtype: float64\n",
      "\n",
      "Imputed numeric columns with median.\n",
      "Applied 1st–99th percentile clipping on numeric feature columns.\n",
      "\n",
      "Dropped 0 rows with residual NaNs after imputation.\n",
      "\n",
      "Final missing values per column:\n",
      " male               0\n",
      "age                0\n",
      "education          0\n",
      "currentSmoker      0\n",
      "cigsPerDay         0\n",
      "BPMeds             0\n",
      "prevalentStroke    0\n",
      "prevalentHyp       0\n",
      "diabetes           0\n",
      "totChol            0\n",
      "sysBP              0\n",
      "diaBP              0\n",
      "BMI                0\n",
      "heartRate          0\n",
      "glucose            0\n",
      "TenYearCHD         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "fake_missing_values = [\"NA\", \"N/A\", \"?\", \" \", \"\"]\n",
    "df = df.replace(fake_missing_values, np.nan)\n",
    "\n",
    "print(\"\\nMissing values per column after normalizing fake NAs:\\n\", df.isna().sum())\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Robust numeric preprocessing:\n",
    "# - Drop rows with missing target\n",
    "# - Drop very high-missing numeric columns (>40% missing)\n",
    "# - Median-impute remaining numeric features\n",
    "# - Light outlier clipping (1st–99th percentile) on features\n",
    "# ------------------------------------------------------------------\n",
    "TARGET_COL = \"TenYearCHD\"\n",
    "\n",
    "# 1) Drop rows where the target is missing (cannot be used for supervised learning)\n",
    "if TARGET_COL in df.columns:\n",
    "    before_rows = df.shape[0]\n",
    "    df = df[~df[TARGET_COL].isna()].copy()\n",
    "    dropped_target = before_rows - df.shape[0]\n",
    "    print(f\"Dropped {dropped_target} rows with missing {TARGET_COL}.\")\n",
    "\n",
    "# 2) Work only with numeric columns for imputation\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(\"\\nNumeric columns detected (for imputation/outlier handling):\\n\", num_cols)\n",
    "\n",
    "if num_cols:\n",
    "    # Fraction of missing in each numeric column\n",
    "    missing_frac = df[num_cols].isna().mean().sort_values(ascending=False)\n",
    "    print(\"\\nNumeric missing fraction (pre‑imputation):\\n\", missing_frac)\n",
    "\n",
    "    # 3) Drop numeric columns with very high missingness\n",
    "    high_missing = missing_frac[missing_frac > 0.40].index.tolist()\n",
    "    if high_missing:\n",
    "        print(\"\\nDropping high‑missing numeric columns (>40% missing):\", high_missing)\n",
    "        df = df.drop(columns=high_missing)\n",
    "        num_cols = [c for c in num_cols if c not in high_missing]\n",
    "\n",
    "    # 4) Median imputation for remaining numeric columns\n",
    "    if num_cols:\n",
    "        imputer = SimpleImputer(strategy=\"median\")\n",
    "        df[num_cols] = imputer.fit_transform(df[num_cols])\n",
    "        print(\"\\nImputed numeric columns with median.\")\n",
    "\n",
    "        # 5) Light outlier clipping on feature columns (not on the target)\n",
    "        clip_cols = [c for c in num_cols if c != TARGET_COL]\n",
    "        for col in clip_cols:\n",
    "            lower = df[col].quantile(0.01)\n",
    "            upper = df[col].quantile(0.99)\n",
    "            df[col] = df[col].clip(lower, upper)\n",
    "        print(\"Applied 1st–99th percentile clipping on numeric feature columns.\")\n",
    "\n",
    "# 6) Final sanity check: drop any remaining rows with NaNs anywhere\n",
    "before_rows = df.shape[0]\n",
    "df = df.dropna(axis=0, how=\"any\")\n",
    "after_rows = df.shape[0]\n",
    "print(f\"\\nDropped {before_rows - after_rows} rows with residual NaNs after imputation.\")\n",
    "print(\"\\nFinal missing values per column:\\n\", df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9a3c86",
   "metadata": {
    "id": "7e9a3c86",
    "papermill": {
     "duration": 0.004293,
     "end_time": "2025-10-24T15:56:53.845565",
     "exception": false,
     "start_time": "2025-10-24T15:56:53.841272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# 3. Feature engineering (pulse pressure, MAP, interactions)\n",
    " As described in paper (pulse pressure, mean arterial pressure, Age*SystolicBP)\n",
    " The framingham dataset columns: check names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e947a9c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T15:56:53.855589Z",
     "iopub.status.busy": "2025-10-24T15:56:53.855205Z",
     "iopub.status.idle": "2025-10-24T15:56:53.869796Z",
     "shell.execute_reply": "2025-10-24T15:56:53.869105Z"
    },
    "id": "e947a9c8",
    "outputId": "7d849fc1-98c2-4085-856c-8683bf8d3439",
    "papermill": {
     "duration": 0.020808,
     "end_time": "2025-10-24T15:56:53.870954",
     "exception": false,
     "start_time": "2025-10-24T15:56:53.850146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['male', 'age', 'education', 'currentSmoker', 'cigsPerDay', 'BPMeds', 'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose', 'TenYearCHD']\n",
      "After FE shape: (4238, 19)\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# Typical columns in this dataset include:\n",
    "# 'male', 'age', 'education', 'currentSmoker', 'cigsPerDay', 'BPMeds',\n",
    "# 'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP',\n",
    "# 'diaBP', 'BMI', 'heartRate', 'glucose', 'TenYearCHD'\n",
    "\n",
    "# Create features if exist\n",
    "if 'sysBP' in df.columns and 'diaBP' in df.columns:\n",
    "    df['pulse_pressure'] = df['sysBP'] - df['diaBP']\n",
    "    df['MAP'] = (2 * df['diaBP'] + df['sysBP']) / 3\n",
    "\n",
    "if 'age' in df.columns and 'sysBP' in df.columns:\n",
    "    df['age_x_sysBP'] = df['age'] * df['sysBP']\n",
    "\n",
    "# Drop any redundant columns if needed (none for now)\n",
    "print(\"After FE shape:\", df.shape)\n",
    "\n",
    "# Separate features and target\n",
    "TARGET = 'TenYearCHD'\n",
    "if TARGET not in df.columns:\n",
    "    raise ValueError(\"Target TenYearCHD not found in dataset\")\n",
    "\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c432b5",
   "metadata": {
    "id": "a2c432b5",
    "papermill": {
     "duration": 0.004679,
     "end_time": "2025-10-24T15:56:53.880176",
     "exception": false,
     "start_time": "2025-10-24T15:56:53.875497",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. mRMR implementation (simple greedy using mutual information)\n",
    "Paper used mRMR producing 10 features; we'll implement greedy mRMR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cd3a04",
   "metadata": {
    "id": "01cd3a04"
   },
   "source": [
    "### what is mRMR and what are we using from it?\n",
    "\n",
    "**mRMR (Minimum Redundancy, Maximum Relevance)** is a supervised feature selection strategy:\n",
    "\n",
    "- **Maximum relevance:** pick features that individually have high mutual information with the target (`TenYearCHD`).  \n",
    "  - Mutual information measures how much knowing a feature reduces uncertainty about the label.\n",
    "- **Minimum redundancy:** avoid selecting features that are highly correlated with each other.  \n",
    "  - If two features say almost the same thing, keeping both adds complexity but little new information.\n",
    "\n",
    "In this notebook, `mrmr_select`:\n",
    "\n",
    "1. Computes mutual information between each feature and `y`.  \n",
    "2. Starts with the single most relevant feature.  \n",
    "3. Iteratively adds features that maximize:  \n",
    "   \n",
    "\n",
    "   `score(feature) = relevance_to_target − average_redundancy_to_already_selected`\n",
    "\n",
    "4. Stops after selecting `k = 10` features.\n",
    "\n",
    "We then build **`X_mrmr`** by taking only these selected columns:\n",
    "\n",
    "```python\n",
    "X_mrmr = X[mrmr_features].copy()\n",
    "```\n",
    "\n",
    "This gives us a **compact, human‑understandable set of important predictors** which we can compare against:\n",
    "\n",
    "- `X_orig` — all engineered features  \n",
    "- `X_pca_df` — 12 PCA components (dense, decorrelated representation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceed5de5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T15:56:53.890251Z",
     "iopub.status.busy": "2025-10-24T15:56:53.889783Z",
     "iopub.status.idle": "2025-10-24T15:56:54.339018Z",
     "shell.execute_reply": "2025-10-24T15:56:54.337947Z"
    },
    "id": "ceed5de5",
    "outputId": "30d591c0-53ac-45b1-ae74-7d77af405d2e",
    "papermill": {
     "duration": 0.455648,
     "end_time": "2025-10-24T15:56:54.340201",
     "exception": false,
     "start_time": "2025-10-24T15:56:53.884553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mRMR selected features: ['age_x_sysBP', 'male', 'diabetes', 'education', 'heartRate', 'BPMeds', 'currentSmoker', 'totChol', 'glucose', 'BMI']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "def mrmr_select(X_df, y_series, k):\n",
    "    X_np = X_df.copy()\n",
    "    features = list(X_np.columns)\n",
    "    mi = mutual_info_classif(X_np, y_series, discrete_features='auto', random_state=42)\n",
    "    mi_dict = dict(zip(features, mi))\n",
    "    selected = []\n",
    "    # 1) pick feature with highest MI\n",
    "    first = max(mi_dict, key=mi_dict.get)\n",
    "    selected.append(first)\n",
    "    while len(selected) < k:\n",
    "        candidates = [f for f in features if f not in selected]\n",
    "        best_score = -np.inf\n",
    "        best_feat = None\n",
    "        for f in candidates:\n",
    "            relevance = mi_dict[f]\n",
    "            redundancy = 0.0\n",
    "            if len(selected) > 0:\n",
    "                # compute avg pairwise MI between f and selected features\n",
    "                redundances = []\n",
    "                for s in selected:\n",
    "                    redundances.append(mutual_info_classif(X_np[[f, s]], y_series, discrete_features='auto', random_state=0)[0] if False else mutual_info_classif(X_np[[f]], X_np[s])[0] if False else 0.0)\n",
    "                # computing redundancy via absolute correlation as proxy (faster)\n",
    "                redundances = [abs(np.corrcoef(X_np[f], X_np[s])[0,1]) for s in selected]\n",
    "                redundancy = np.mean(redundances)\n",
    "            # score = relevance - redundancy (mRMR idea)\n",
    "            score = relevance - redundancy\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_feat = f\n",
    "        if best_feat is None:\n",
    "            break\n",
    "        selected.append(best_feat)\n",
    "    return selected\n",
    "\n",
    "# We'll attempt to pick 10 features via mRMR as in paper\n",
    "mrmr_k = 10\n",
    "mrmr_features = mrmr_select(X, y, mrmr_k)\n",
    "print(\"mRMR selected features:\", mrmr_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f56c48f",
   "metadata": {
    "id": "3f56c48f",
    "papermill": {
     "duration": 0.004799,
     "end_time": "2025-10-24T15:56:54.350045",
     "exception": false,
     "start_time": "2025-10-24T15:56:54.345246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. PCA: scale then PCA to 12 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7e3eb50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T15:56:54.360461Z",
     "iopub.status.busy": "2025-10-24T15:56:54.360226Z",
     "iopub.status.idle": "2025-10-24T15:56:54.512129Z",
     "shell.execute_reply": "2025-10-24T15:56:54.509981Z"
    },
    "id": "e7e3eb50",
    "outputId": "25e2abda-c2d9-4de7-919a-92d11c0708f4",
    "papermill": {
     "duration": 0.161103,
     "end_time": "2025-10-24T15:56:54.515650",
     "exception": false,
     "start_time": "2025-10-24T15:56:54.354547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA 12 components explained variance: 0.9626\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "pca = PCA(n_components=12, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "explained = pca.explained_variance_ratio_.sum()\n",
    "print(f\"PCA 12 components explained variance: {explained:.4f}\")\n",
    "\n",
    "# We'll build three feature sets per paper: Original (all), mRMR (selected), PCA (12 comps)\n",
    "X_orig = X.copy()\n",
    "X_mrmr = X[mrmr_features].copy()\n",
    "X_pca_df = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(X_pca.shape[1])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb479e7",
   "metadata": {
    "id": "4bb479e7",
    "papermill": {
     "duration": 0.007479,
     "end_time": "2025-10-24T15:56:54.533981",
     "exception": false,
     "start_time": "2025-10-24T15:56:54.526502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Balancing: manual oversampling minority to match majority \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a4e2ad1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T15:56:54.551223Z",
     "iopub.status.busy": "2025-10-24T15:56:54.550644Z",
     "iopub.status.idle": "2025-10-24T15:56:54.581439Z",
     "shell.execute_reply": "2025-10-24T15:56:54.580727Z"
    },
    "id": "9a4e2ad1",
    "outputId": "528c5557-24e3-48a6-e754-6d35da9445c2",
    "papermill": {
     "duration": 0.041336,
     "end_time": "2025-10-24T15:56:54.583439",
     "exception": false,
     "start_time": "2025-10-24T15:56:54.542103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After balancing PCA set: (7188, 12) TenYearCHD\n",
      "0    3594\n",
      "1    3594\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def manual_oversample(Xf, yf):\n",
    "    counts = yf.value_counts()\n",
    "    if counts.min() < 10:\n",
    "        print(\"Minority class < 10, skipping oversampling.\")\n",
    "        return Xf, yf\n",
    "    if counts.nunique() == 1:\n",
    "        print(\"Only one class present, skipping oversampling.\")\n",
    "        return Xf, yf\n",
    "    maj = counts.idxmax()\n",
    "    max_count = counts.max()\n",
    "    X_res = Xf.copy()\n",
    "    y_res = yf.copy()\n",
    "    for cls, cnt in counts.items():\n",
    "        if cnt < max_count:\n",
    "            need = max_count - cnt\n",
    "            idx = np.where(yf == cls)[0]\n",
    "            # sample with replacement\n",
    "            choice = np.random.choice(idx, size=need, replace=True)\n",
    "            X_res = pd.concat([X_res, Xf.iloc[choice]], axis=0, ignore_index=True)\n",
    "            y_res = pd.concat([y_res, yf.iloc[choice]], axis=0, ignore_index=True)\n",
    "    return X_res, y_res\n",
    "\n",
    "# Example: apply balancing for PCA-set (convert to df)\n",
    "X_pca_df_reset = pd.DataFrame(X_pca_df).reset_index(drop=True)\n",
    "y_reset = y.reset_index(drop=True)\n",
    "X_pca_bal, y_pca_bal = manual_oversample(X_pca_df_reset, y_reset)\n",
    "print(\"After balancing PCA set:\", X_pca_bal.shape, y_pca_bal.value_counts())\n",
    "\n",
    "# For original and mRMR sets:\n",
    "X_orig_reset = X_orig.reset_index(drop=True)\n",
    "X_mrmr_reset = X_mrmr.reset_index(drop=True)\n",
    "X_orig_bal, y_orig_bal = manual_oversample(X_orig_reset, y_reset)\n",
    "X_mrmr_bal, y_mrmr_bal = manual_oversample(X_mrmr_reset, y_reset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced2cd4c",
   "metadata": {
    "id": "ced2cd4c",
    "papermill": {
     "duration": 0.008021,
     "end_time": "2025-10-24T15:56:54.601633",
     "exception": false,
     "start_time": "2025-10-24T15:56:54.593612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. Train/test split (70/30) — per paper they later use 10-fold CV; we'll do both:\n",
    "  First compute 10-fold stratified CV metrics for each model and each feature set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bb1e20",
   "metadata": {
    "id": "85bb1e20"
   },
   "source": [
    "### Where and why we try different models\n",
    "\n",
    "The function `evaluate_models` is our **comprehensive model comparison engine** with multiple configuration levels:\n",
    "\n",
    "- It creates a 10‑fold `StratifiedKFold` object so that each fold has a similar class balance.  \n",
    "- It defines **multiple configurations for each model type** (simple → medium → complex):\n",
    "  - **ExtraTreesClassifier**: 3 configurations (50/100/150 estimators with varying complexity)\n",
    "  - **RandomForestClassifier**: 3 configurations (different n_estimators, min_samples settings, class weighting)\n",
    "  - **GradientBoostingClassifier**: 3 configurations (varying learning rates, depths, and subsampling)\n",
    "  - **DecisionTreeClassifier**: 3 configurations (max_depth from 3 to None)\n",
    "  - **LogisticRegression**: 3 configurations (varying C parameter and class weighting)\n",
    "  - **SVC (RBF kernel)**: 3 configurations (different C values and class weighting)\n",
    "  - **MLPClassifier**: 3 configurations (1-layer, 2-layer, 3-layer networks with different sizes)\n",
    "  - **XGBClassifier** (if installed): 3 configurations (different learning rates and depths)\n",
    "\n",
    "For every model configuration, it runs `cross_validate` with metrics:\n",
    "\n",
    "- accuracy  \n",
    "- precision  \n",
    "- recall  \n",
    "- f1  \n",
    "- roc_auc  \n",
    "\n",
    "and also measures:\n",
    "\n",
    "- **Model size** (memory footprint in MB via pickle serialization)\n",
    "- **Training time** (seconds to fit on full dataset)\n",
    "- **Cross-validation time** (total time for 10-fold CV)\n",
    "- **Prediction latency** (milliseconds per sample, averaged over 100 predictions)\n",
    "\n",
    "Then we call:\n",
    "\n",
    "```python\n",
    "res_orig = evaluate_models(X_orig_bal, y_orig_bal, desc=\"Original (balanced)\")\n",
    "res_mrmr = evaluate_models(X_mrmr_bal, y_mrmr_bal, desc=\"mRMR (balanced)\")\n",
    "res_pca  = evaluate_models(X_pca_bal, y_pca_bal,   desc=\"PCA (balanced)\")\n",
    "```\n",
    "\n",
    "So we are explicitly comparing:\n",
    "\n",
    "1. **Different feature sets**: original vs. mRMR vs. PCA.  \n",
    "2. **Different model families**: tree ensembles, boosting, linear models, SVMs, neural networks, etc.\n",
    "3. **Different complexity levels**: simple (fast, less prone to overfitting) to complex (more capacity, may need more data).\n",
    "4. **Performance vs. deployment tradeoffs**: accuracy vs. model size vs. prediction speed.\n",
    "\n",
    "This lets us **see empirically** which combination (model + configuration + feature representation) gives the best balance of metrics before we commit to tuning one model further. The results are sorted by accuracy in the summary table for easy comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c3485",
   "metadata": {},
   "source": [
    "### Model Comparison: Multiple Configurations for Each Model Type\n",
    "\n",
    "Below are the models we'll evaluate, with **simple, medium, and complex** configurations for each to explore the bias-variance tradeoff:\n",
    "\n",
    "#### 1. **ExtraTreesClassifier** (Extremely Randomized Trees)\n",
    "- **Simple**: `n_estimators=50`, `max_features='sqrt'` — Fast, baseline configuration\n",
    "- **Medium**: `n_estimators=100`, `min_samples_split=4` — More trees, slight regularization\n",
    "- **Complex**: `n_estimators=150`, `max_features=None` — Maximum capacity, uses all features\n",
    "- **How it works**: Like Random Forest, but makes splits completely at random (doesn't search for best threshold)\n",
    "- **Pros**: Very fast training, less prone to overfitting, good for high-dimensional data\n",
    "- **Cons**: May need more trees than Random Forest for same accuracy\n",
    "\n",
    "#### 2. **RandomForestClassifier**\n",
    "- **Simple**: `n_estimators=50` — Baseline ensemble\n",
    "- **Medium**: `n_estimators=100`, `min_samples_split=4`, `min_samples_leaf=2` — More regularization\n",
    "- **Complex**: `n_estimators=150`, `class_weight='balanced'` — Handles class imbalance explicitly\n",
    "- **How it works**: Ensemble of decision trees, each trained on bootstrap sample with random feature subsets\n",
    "- **Pros**: Robust, handles non-linear relationships, built-in feature importance\n",
    "- **Cons**: Can be slow on large datasets, less interpretable than single tree\n",
    "\n",
    "#### 3. **GradientBoostingClassifier**\n",
    "- **Simple**: `n_estimators=50`, `lr=0.1`, `max_depth=3` — Fast boosting baseline\n",
    "- **Medium**: `n_estimators=100`, `lr=0.05`, `subsample=0.8` — Lower learning rate, stochastic boosting\n",
    "- **Complex**: `n_estimators=150`, `lr=0.03`, `max_depth=4` — Deeper trees, more iterations\n",
    "- **How it works**: Builds trees sequentially, each correcting errors of previous ones\n",
    "- **Pros**: Often best performance, handles feature interactions well\n",
    "- **Cons**: Slower training, prone to overfitting if not tuned, sensitive to outliers\n",
    "\n",
    "#### 4. **DecisionTreeClassifier**\n",
    "- **Simple**: `max_depth=3` — Shallow tree, highly interpretable\n",
    "- **Medium**: `max_depth=6`, `min_samples_split=4` — Moderate depth with regularization\n",
    "- **Complex**: `max_depth=None` — Full tree, can overfit\n",
    "- **How it works**: Single tree that splits data based on feature thresholds to maximize purity\n",
    "- **Pros**: Highly interpretable, fast prediction, no feature scaling needed\n",
    "- **Cons**: Very prone to overfitting (especially complex version), unstable\n",
    "\n",
    "#### 5. **LogisticRegression**\n",
    "- **Simple**: `C=0.3`, no class weighting — Strong regularization\n",
    "- **Medium**: `C=1.0`, `class_weight='balanced'` — Moderate regularization, handles imbalance\n",
    "- **Complex**: `C=3.0`, `class_weight='balanced'` — Less regularization, more model flexibility\n",
    "- **How it works**: Linear model using logistic (sigmoid) function for binary classification\n",
    "- **Pros**: Fast, interpretable coefficients, works well with linearly separable data\n",
    "- **Cons**: Cannot capture complex non-linear patterns without feature engineering\n",
    "\n",
    "#### 6. **SVC (Support Vector Classifier with RBF kernel)**\n",
    "- **Simple**: `C=0.8`, `gamma='scale'` — Moderate margin, standard gamma\n",
    "- **Medium**: `C=2.0`, `class_weight='balanced'` — Tighter margin, handles imbalance\n",
    "- **Complex**: `C=4.0`, `class_weight='balanced'` — Very tight margin, maximum flexibility\n",
    "- **How it works**: Finds optimal hyperplane in high-dimensional space via kernel trick\n",
    "- **Pros**: Effective in high dimensions, memory efficient, versatile via kernels\n",
    "- **Cons**: Slow on large datasets, sensitive to hyperparameters and scaling\n",
    "\n",
    "#### 7. **MLPClassifier** (Multi-Layer Perceptron / Neural Network)\n",
    "- **Simple**: `hidden_layer_sizes=(32,)` — Single hidden layer with 32 neurons\n",
    "- **Medium**: `hidden_layer_sizes=(64, 32)` — Two layers for deeper representations\n",
    "- **Complex**: `hidden_layer_sizes=(128, 64, 32)` — Three layers, maximum capacity\n",
    "- **How it works**: Artificial neural network with backpropagation training\n",
    "- **Pros**: Can learn complex non-linear patterns, powerful for high-dimensional data\n",
    "- **Cons**: Needs careful tuning, sensitive to feature scaling, \"black box\", can overfit\n",
    "\n",
    "#### 8. **XGBClassifier** (XGBoost - if installed)\n",
    "- **Simple**: `n_estimators=50`, `lr=0.1`, `max_depth=4` — Fast baseline\n",
    "- **Medium**: `n_estimators=100`, `lr=0.05`, `max_depth=5` — More iterations, deeper trees\n",
    "- **Complex**: `n_estimators=150`, `lr=0.03`, `max_depth=6` — Maximum capacity\n",
    "- **How it works**: Optimized gradient boosting with regularization and parallel processing\n",
    "- **Pros**: State-of-the-art performance, handles missing values, built-in regularization\n",
    "- **Cons**: Many hyperparameters to tune, can overfit on small datasets\n",
    "\n",
    "---\n",
    "\n",
    "**What we measure for each configuration:**\n",
    "- **Cross-validation metrics**: accuracy, precision, recall, F1, ROC-AUC (mean ± std across 10 folds)\n",
    "- **Model size**: memory footprint in MB after serialization (important for deployment)\n",
    "- **Training time**: how long it takes to train on all data (seconds)\n",
    "- **CV time**: total cross-validation time (includes all 10 folds)\n",
    "- **Prediction latency**: average time to predict a single sample in milliseconds (critical for real-time applications)\n",
    "\n",
    "The results are **sorted by accuracy** in the summary table, making it easy to identify top performers while considering deployment constraints like model size and prediction speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35dc5d94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T15:56:54.619043Z",
     "iopub.status.busy": "2025-10-24T15:56:54.618183Z",
     "iopub.status.idle": "2025-10-24T16:00:23.618435Z",
     "shell.execute_reply": "2025-10-24T16:00:23.617451Z"
    },
    "id": "35dc5d94",
    "outputId": "a359129f-012d-4c72-cdde-46f4035a94ee",
    "papermill": {
     "duration": 209.015341,
     "end_time": "2025-10-24T16:00:23.624826",
     "exception": false,
     "start_time": "2025-10-24T15:56:54.609485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "🔹 STEP 1/3: Evaluating on ORIGINAL feature set (all features)\n",
      "\n",
      "==========================================\n",
      "=== Evaluating for Original (balanced) ===\n",
      "==========================================\n",
      "\n",
      "\n",
      "ExtraTrees_simple\n",
      "-----------------\n",
      "  Configuration: ExtraTrees: n_estimators=50, max_depth=None, max_features='sqrt'\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9907 ±  0.0019\n",
      "    precision   :  0.9857 ±  0.0036\n",
      "    recall      :  0.9958 ±  0.0036\n",
      "    f1          :  0.9907 ±  0.0019\n",
      "    roc_auc     :  0.9985 ±  0.0017\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :   11.20 MB\n",
      "    Training Time     : 0.10s\n",
      "    CV Time (total)   : 5.30s\n",
      "    Prediction Latency:  17.511 ms/sample\n",
      "\n",
      "ExtraTrees_medium\n",
      "-----------------\n",
      "  Configuration: ExtraTrees: n_estimators=100, min_samples_split=4, max_features='sqrt'\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9896 ±  0.0033\n",
      "    precision   :  0.9841 ±  0.0051\n",
      "    recall      :  0.9953 ±  0.0043\n",
      "    f1          :  0.9896 ±  0.0033\n",
      "    roc_auc     :  0.9983 ±  0.0018\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :   22.22 MB\n",
      "    Training Time     : 0.19s\n",
      "    CV Time (total)   : 1.56s\n",
      "    Prediction Latency:  17.903 ms/sample\n",
      "\n",
      "ExtraTrees_complex\n",
      "------------------\n",
      "  Configuration: ExtraTrees: n_estimators=150, max_features=None, min_samples_split=4\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9875 ±  0.0025\n",
      "    precision   :  0.9798 ±  0.0066\n",
      "    recall      :  0.9956 ±  0.0042\n",
      "    f1          :  0.9876 ±  0.0024\n",
      "    roc_auc     :  0.9984 ±  0.0020\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :   21.92 MB\n",
      "    Training Time     : 0.47s\n",
      "    CV Time (total)   : 3.64s\n",
      "    Prediction Latency:  28.183 ms/sample\n",
      "\n",
      "RandomForest_simple\n",
      "-------------------\n",
      "  Configuration: RandomForest: n_estimators=50, max_features='sqrt'\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9763 ±  0.0049\n",
      "    precision   :  0.9581 ±  0.0086\n",
      "    recall      :  0.9964 ±  0.0039\n",
      "    f1          :  0.9768 ±  0.0047\n",
      "    roc_auc     :  0.9982 ±  0.0020\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    5.49 MB\n",
      "    Training Time     : 0.16s\n",
      "    CV Time (total)   : 1.15s\n",
      "    Prediction Latency:  18.077 ms/sample\n",
      "\n",
      "RandomForest_medium\n",
      "-------------------\n",
      "  Configuration: RandomForest: n_estimators=100, min_samples_split=4, min_samples_leaf=2\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9640 ±  0.0053\n",
      "    precision   :  0.9414 ±  0.0097\n",
      "    recall      :  0.9897 ±  0.0054\n",
      "    f1          :  0.9649 ±  0.0050\n",
      "    roc_auc     :  0.9970 ±  0.0019\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    9.79 MB\n",
      "    Training Time     : 0.28s\n",
      "    CV Time (total)   : 2.15s\n",
      "    Prediction Latency:  18.061 ms/sample\n",
      "\n",
      "RandomForest_complex\n",
      "--------------------\n",
      "  Configuration: RandomForest: n_estimators=150, class_weight='balanced'\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9757 ±  0.0054\n",
      "    precision   :  0.9575 ±  0.0095\n",
      "    recall      :  0.9956 ±  0.0042\n",
      "    f1          :  0.9761 ±  0.0051\n",
      "    roc_auc     :  0.9983 ±  0.0016\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :   16.52 MB\n",
      "    Training Time     : 0.64s\n",
      "    CV Time (total)   : 3.88s\n",
      "    Prediction Latency:  30.719 ms/sample\n",
      "\n",
      "GB_simple\n",
      "---------\n",
      "  Configuration: GradientBoosting: n_estimators=50, lr=0.1, max_depth=3\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7042 ±  0.0201\n",
      "    precision   :  0.7054 ±  0.0209\n",
      "    recall      :  0.7020 ±  0.0342\n",
      "    f1          :  0.7033 ±  0.0225\n",
      "    roc_auc     :  0.7790 ±  0.0172\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.07 MB\n",
      "    Training Time     : 0.65s\n",
      "    CV Time (total)   : 2.20s\n",
      "    Prediction Latency:   1.544 ms/sample\n",
      "\n",
      "GB_medium\n",
      "---------\n",
      "  Configuration: GradientBoosting: n_estimators=100, lr=0.05, subsample=0.8\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7076 ±  0.0222\n",
      "    precision   :  0.7073 ±  0.0218\n",
      "    recall      :  0.7087 ±  0.0357\n",
      "    f1          :  0.7076 ±  0.0245\n",
      "    roc_auc     :  0.7819 ±  0.0178\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.13 MB\n",
      "    Training Time     : 2.23s\n",
      "    CV Time (total)   : 5.08s\n",
      "    Prediction Latency:   3.008 ms/sample\n",
      "\n",
      "GB_complex\n",
      "----------\n",
      "  Configuration: GradientBoosting: n_estimators=150, lr=0.03, max_depth=4, subsample=0.8\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7366 ±  0.0192\n",
      "    precision   :  0.7322 ±  0.0192\n",
      "    recall      :  0.7468 ±  0.0318\n",
      "    f1          :  0.7391 ±  0.0207\n",
      "    roc_auc     :  0.8238 ±  0.0177\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.36 MB\n",
      "    Training Time     : 3.26s\n",
      "    CV Time (total)   : 10.34s\n",
      "    Prediction Latency:   1.164 ms/sample\n",
      "\n",
      "DecisionTree_simple\n",
      "-------------------\n",
      "  Configuration: DecisionTree: max_depth=3\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6735 ±  0.0222\n",
      "    precision   :  0.6948 ±  0.0282\n",
      "    recall      :  0.6211 ±  0.0368\n",
      "    f1          :  0.6551 ±  0.0251\n",
      "    roc_auc     :  0.7276 ±  0.0215\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.00 MB\n",
      "    Training Time     : 0.02s\n",
      "    CV Time (total)   : 0.10s\n",
      "    Prediction Latency:   1.184 ms/sample\n",
      "\n",
      "DecisionTree_medium\n",
      "-------------------\n",
      "  Configuration: DecisionTree: max_depth=6, min_samples_split=4\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7173 ±  0.0190\n",
      "    precision   :  0.7052 ±  0.0218\n",
      "    recall      :  0.7488 ±  0.0437\n",
      "    f1          :  0.7255 ±  0.0223\n",
      "    roc_auc     :  0.7729 ±  0.0189\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.01 MB\n",
      "    Training Time     : 0.05s\n",
      "    CV Time (total)   : 0.13s\n",
      "    Prediction Latency:   1.394 ms/sample\n",
      "\n",
      "DecisionTree_complex\n",
      "--------------------\n",
      "  Configuration: DecisionTree: max_depth=None, min_samples_split=2, min_samples_leaf=1\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9193 ±  0.0051\n",
      "    precision   :  0.8643 ±  0.0078\n",
      "    recall      :  0.9950 ±  0.0049\n",
      "    f1          :  0.9250 ±  0.0045\n",
      "    roc_auc     :  0.9193 ±  0.0051\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.10 MB\n",
      "    Training Time     : 0.13s\n",
      "    CV Time (total)   : 0.20s\n",
      "    Prediction Latency:   1.244 ms/sample\n",
      "\n",
      "LogReg_simple\n",
      "-------------\n",
      "  Configuration: LogReg: C=0.3, no class_weight, max_iter=1000\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6676 ±  0.0210\n",
      "    precision   :  0.6743 ±  0.0226\n",
      "    recall      :  0.6494 ±  0.0343\n",
      "    f1          :  0.6612 ±  0.0238\n",
      "    roc_auc     :  0.7257 ±  0.0179\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.00 MB\n",
      "    Training Time     : 0.98s\n",
      "    CV Time (total)   : 1.71s\n",
      "    Prediction Latency:   1.511 ms/sample\n",
      "\n",
      "LogReg_medium\n",
      "-------------\n",
      "  Configuration: LogReg: C=1.0, class_weight='balanced', max_iter=1500\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6697 ±  0.0196\n",
      "    precision   :  0.6760 ±  0.0215\n",
      "    recall      :  0.6531 ±  0.0349\n",
      "    f1          :  0.6638 ±  0.0226\n",
      "    roc_auc     :  0.7264 ±  0.0183\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.00 MB\n",
      "    Training Time     : 1.07s\n",
      "    CV Time (total)   : 2.48s\n",
      "    Prediction Latency:   0.935 ms/sample\n",
      "\n",
      "LogReg_complex\n",
      "--------------\n",
      "  Configuration: LogReg: C=3.0, class_weight='balanced', max_iter=2000\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6713 ±  0.0198\n",
      "    precision   :  0.6769 ±  0.0224\n",
      "    recall      :  0.6567 ±  0.0337\n",
      "    f1          :  0.6661 ±  0.0222\n",
      "    roc_auc     :  0.7262 ±  0.0186\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.00 MB\n",
      "    Training Time     : 1.01s\n",
      "    CV Time (total)   : 3.49s\n",
      "    Prediction Latency:   0.396 ms/sample\n",
      "\n",
      "SVC_simple\n",
      "----------\n",
      "  Configuration: SVC RBF: C=0.8, gamma='scale', no class_weight\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6434 ±  0.0184\n",
      "    precision   :  0.6525 ±  0.0176\n",
      "    recall      :  0.6135 ±  0.0351\n",
      "    f1          :  0.6321 ±  0.0240\n",
      "    roc_auc     :  0.7038 ±  0.0179\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.85 MB\n",
      "    Training Time     : 8.58s\n",
      "    CV Time (total)   : 30.97s\n",
      "    Prediction Latency:   0.943 ms/sample\n",
      "\n",
      "SVC_medium\n",
      "----------\n",
      "  Configuration: SVC RBF: C=2.0, gamma='scale', class_weight='balanced'\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6497 ±  0.0175\n",
      "    precision   :  0.6543 ±  0.0171\n",
      "    recall      :  0.6350 ±  0.0314\n",
      "    f1          :  0.6442 ±  0.0215\n",
      "    roc_auc     :  0.7058 ±  0.0185\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.84 MB\n",
      "    Training Time     : 8.58s\n",
      "    CV Time (total)   : 31.21s\n",
      "    Prediction Latency:   0.959 ms/sample\n",
      "\n",
      "SVC_complex\n",
      "-----------\n",
      "  Configuration: SVC RBF: C=4.0, gamma='scale', class_weight='balanced'\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6498 ±  0.0178\n",
      "    precision   :  0.6500 ±  0.0163\n",
      "    recall      :  0.6492 ±  0.0363\n",
      "    f1          :  0.6492 ±  0.0229\n",
      "    roc_auc     :  0.7071 ±  0.0184\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.84 MB\n",
      "    Training Time     : 9.24s\n",
      "    CV Time (total)   : 36.11s\n",
      "    Prediction Latency:   0.880 ms/sample\n",
      "\n",
      "MLP_simple\n",
      "----------\n",
      "  Configuration: MLP: hidden_layer_sizes=(32,), alpha=0.001, max_iter=400\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6202 ±  0.0263\n",
      "    precision   :  0.6162 ±  0.0292\n",
      "    recall      :  0.6550 ±  0.1101\n",
      "    f1          :  0.6288 ±  0.0493\n",
      "    roc_auc     :  0.6656 ±  0.0263\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.02 MB\n",
      "    Training Time     : 0.19s\n",
      "    CV Time (total)   : 1.00s\n",
      "    Prediction Latency:   0.477 ms/sample\n",
      "\n",
      "MLP_medium\n",
      "----------\n",
      "  Configuration: MLP: hidden_layer_sizes=(64, 32), alpha=0.0005, max_iter=500\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6501 ±  0.0153\n",
      "    precision   :  0.6420 ±  0.0290\n",
      "    recall      :  0.6909 ±  0.0601\n",
      "    f1          :  0.6630 ±  0.0166\n",
      "    roc_auc     :  0.7075 ±  0.0235\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.09 MB\n",
      "    Training Time     : 0.99s\n",
      "    CV Time (total)   : 2.80s\n",
      "    Prediction Latency:   0.497 ms/sample\n",
      "\n",
      "MLP_complex\n",
      "-----------\n",
      "  Configuration: MLP: hidden_layer_sizes=(128, 64, 32), alpha=0.001, batch_size=64, max_iter=600\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6625 ±  0.0209\n",
      "    precision   :  0.6666 ±  0.0294\n",
      "    recall      :  0.6606 ±  0.0890\n",
      "    f1          :  0.6589 ±  0.0414\n",
      "    roc_auc     :  0.7195 ±  0.0212\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.30 MB\n",
      "    Training Time     : 2.76s\n",
      "    CV Time (total)   : 14.54s\n",
      "    Prediction Latency:   0.490 ms/sample\n",
      "\n",
      "XGB_simple\n",
      "----------\n",
      "  Configuration: XGBoost: n_estimators=50, lr=0.1, max_depth=4, subsample=0.8, colsample_bytree=0.8\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7316 ±  0.0208\n",
      "    precision   :  0.7257 ±  0.0221\n",
      "    recall      :  0.7457 ±  0.0367\n",
      "    f1          :  0.7351 ±  0.0226\n",
      "    roc_auc     :  0.8156 ±  0.0174\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.08 MB\n",
      "    Training Time     : 0.06s\n",
      "    CV Time (total)   : 0.29s\n",
      "    Prediction Latency:   1.731 ms/sample\n",
      "\n",
      "XGB_medium\n",
      "----------\n",
      "  Configuration: XGBoost: n_estimators=100, lr=0.05, max_depth=5, subsample=0.8, colsample_bytree=0.8\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7728 ±  0.0189\n",
      "    precision   :  0.7563 ±  0.0219\n",
      "    recall      :  0.8061 ±  0.0317\n",
      "    f1          :  0.7800 ±  0.0192\n",
      "    roc_auc     :  0.8645 ±  0.0140\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.23 MB\n",
      "    Training Time     : 0.16s\n",
      "    CV Time (total)   : 0.65s\n",
      "    Prediction Latency:   2.387 ms/sample\n",
      "\n",
      "XGB_complex\n",
      "-----------\n",
      "  Configuration: XGBoost: n_estimators=150, lr=0.03, max_depth=6, subsample=0.85, colsample_bytree=0.9\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.8175 ±  0.0162\n",
      "    precision   :  0.7914 ±  0.0181\n",
      "    recall      :  0.8628 ±  0.0262\n",
      "    f1          :  0.8253 ±  0.0160\n",
      "    roc_auc     :  0.9055 ±  0.0112\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.51 MB\n",
      "    Training Time     : 0.35s\n",
      "    CV Time (total)   : 1.24s\n",
      "    Prediction Latency:   1.954 ms/sample\n",
      "\n",
      "========================================================================================================================\n",
      "SUMMARY COMPARISON - ALL METRICS\n",
      "========================================================================================================================\n",
      "Model               Accuracy  Precision    Recall        F1   ROC-AUC  Size(MB)  Train(s)  Latency(ms)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "ExtraTrees_simple     0.9907     0.9857    0.9958    0.9907    0.9985     11.20      0.10       17.511\n",
      "    Config: ExtraTrees: n_estimators=50, max_depth=None, max_features='sqrt'\n",
      "ExtraTrees_medium     0.9896     0.9841    0.9953    0.9896    0.9983     22.22      0.19       17.903\n",
      "    Config: ExtraTrees: n_estimators=100, min_samples_split=4, max_features='sqrt'\n",
      "ExtraTrees_complex    0.9875     0.9798    0.9956    0.9876    0.9984     21.92      0.47       28.183\n",
      "    Config: ExtraTrees: n_estimators=150, max_features=None, min_samples_split=4\n",
      "RandomForest_simple    0.9763     0.9581    0.9964    0.9768    0.9982      5.49      0.16       18.077\n",
      "    Config: RandomForest: n_estimators=50, max_features='sqrt'\n",
      "RandomForest_complex    0.9757     0.9575    0.9956    0.9761    0.9983     16.52      0.64       30.719\n",
      "    Config: RandomForest: n_estimators=150, class_weight='balanced'\n",
      "RandomForest_medium    0.9640     0.9414    0.9897    0.9649    0.9970      9.79      0.28       18.061\n",
      "    Config: RandomForest: n_estimators=100, min_samples_split=4, min_samples_leaf=2\n",
      "DecisionTree_complex    0.9193     0.8643    0.9950    0.9250    0.9193      0.10      0.13        1.244\n",
      "    Config: DecisionTree: max_depth=None, min_samples_split=2, min_samples_leaf=1\n",
      "XGB_complex           0.8175     0.7914    0.8628    0.8253    0.9055      0.51      0.35        1.954\n",
      "    Config: XGBoost: n_estimators=150, lr=0.03, max_depth=6, subsample=0.85, colsample_bytree=0.9\n",
      "XGB_medium            0.7728     0.7563    0.8061    0.7800    0.8645      0.23      0.16        2.387\n",
      "    Config: XGBoost: n_estimators=100, lr=0.05, max_depth=5, subsample=0.8, colsample_bytree=0.8\n",
      "GB_complex            0.7366     0.7322    0.7468    0.7391    0.8238      0.36      3.26        1.164\n",
      "    Config: GradientBoosting: n_estimators=150, lr=0.03, max_depth=4, subsample=0.8\n",
      "XGB_simple            0.7316     0.7257    0.7457    0.7351    0.8156      0.08      0.06        1.731\n",
      "    Config: XGBoost: n_estimators=50, lr=0.1, max_depth=4, subsample=0.8, colsample_bytree=0.8\n",
      "DecisionTree_medium    0.7173     0.7052    0.7488    0.7255    0.7729      0.01      0.05        1.394\n",
      "    Config: DecisionTree: max_depth=6, min_samples_split=4\n",
      "GB_medium             0.7076     0.7073    0.7087    0.7076    0.7819      0.13      2.23        3.008\n",
      "    Config: GradientBoosting: n_estimators=100, lr=0.05, subsample=0.8\n",
      "GB_simple             0.7042     0.7054    0.7020    0.7033    0.7790      0.07      0.65        1.544\n",
      "    Config: GradientBoosting: n_estimators=50, lr=0.1, max_depth=3\n",
      "DecisionTree_simple    0.6735     0.6948    0.6211    0.6551    0.7276      0.00      0.02        1.184\n",
      "    Config: DecisionTree: max_depth=3\n",
      "LogReg_complex        0.6713     0.6769    0.6567    0.6661    0.7262      0.00      1.01        0.396\n",
      "    Config: LogReg: C=3.0, class_weight='balanced', max_iter=2000\n",
      "LogReg_medium         0.6697     0.6760    0.6531    0.6638    0.7264      0.00      1.07        0.935\n",
      "    Config: LogReg: C=1.0, class_weight='balanced', max_iter=1500\n",
      "LogReg_simple         0.6676     0.6743    0.6494    0.6612    0.7257      0.00      0.98        1.511\n",
      "    Config: LogReg: C=0.3, no class_weight, max_iter=1000\n",
      "MLP_complex           0.6625     0.6666    0.6606    0.6589    0.7195      0.30      2.76        0.490\n",
      "    Config: MLP: hidden_layer_sizes=(128, 64, 32), alpha=0.001, batch_size=64, max_iter=600\n",
      "MLP_medium            0.6501     0.6420    0.6909    0.6630    0.7075      0.09      0.99        0.497\n",
      "    Config: MLP: hidden_layer_sizes=(64, 32), alpha=0.0005, max_iter=500\n",
      "SVC_complex           0.6498     0.6500    0.6492    0.6492    0.7071      0.84      9.24        0.880\n",
      "    Config: SVC RBF: C=4.0, gamma='scale', class_weight='balanced'\n",
      "SVC_medium            0.6497     0.6543    0.6350    0.6442    0.7058      0.84      8.58        0.959\n",
      "    Config: SVC RBF: C=2.0, gamma='scale', class_weight='balanced'\n",
      "SVC_simple            0.6434     0.6525    0.6135    0.6321    0.7038      0.85      8.58        0.943\n",
      "    Config: SVC RBF: C=0.8, gamma='scale', no class_weight\n",
      "MLP_simple            0.6202     0.6162    0.6550    0.6288    0.6656      0.02      0.19        0.477\n",
      "    Config: MLP: hidden_layer_sizes=(32,), alpha=0.001, max_iter=400\n",
      "========================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "🔹 STEP 2/3: Evaluating on mRMR feature set (10 selected features)\n",
      "\n",
      "======================================\n",
      "=== Evaluating for mRMR (balanced) ===\n",
      "======================================\n",
      "\n",
      "\n",
      "ExtraTrees_simple\n",
      "-----------------\n",
      "  Configuration: ExtraTrees: n_estimators=50, max_depth=None, max_features='sqrt'\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9882 ±  0.0031\n",
      "    precision   :  0.9798 ±  0.0052\n",
      "    recall      :  0.9969 ±  0.0019\n",
      "    f1          :  0.9883 ±  0.0031\n",
      "    roc_auc     :  0.9992 ±  0.0011\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :   12.96 MB\n",
      "    Training Time     : 0.13s\n",
      "    CV Time (total)   : 0.95s\n",
      "    Prediction Latency:  17.438 ms/sample\n",
      "\n",
      "ExtraTrees_medium\n",
      "-----------------\n",
      "  Configuration: ExtraTrees: n_estimators=100, min_samples_split=4, max_features='sqrt'\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9882 ±  0.0027\n",
      "    precision   :  0.9795 ±  0.0037\n",
      "    recall      :  0.9972 ±  0.0022\n",
      "    f1          :  0.9883 ±  0.0027\n",
      "    roc_auc     :  0.9992 ±  0.0008\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :   25.51 MB\n",
      "    Training Time     : 0.25s\n",
      "    CV Time (total)   : 1.53s\n",
      "    Prediction Latency:  19.904 ms/sample\n",
      "\n",
      "ExtraTrees_complex\n",
      "------------------\n",
      "  Configuration: ExtraTrees: n_estimators=150, max_features=None, min_samples_split=4\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9816 ±  0.0037\n",
      "    precision   :  0.9671 ±  0.0055\n",
      "    recall      :  0.9972 ±  0.0022\n",
      "    f1          :  0.9819 ±  0.0036\n",
      "    roc_auc     :  0.9992 ±  0.0009\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :   26.30 MB\n",
      "    Training Time     : 0.45s\n",
      "    CV Time (total)   : 3.50s\n",
      "    Prediction Latency:  28.458 ms/sample\n",
      "\n",
      "RandomForest_simple\n",
      "-------------------\n",
      "  Configuration: RandomForest: n_estimators=50, max_features='sqrt'\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9720 ±  0.0047\n",
      "    precision   :  0.9497 ±  0.0084\n",
      "    recall      :  0.9969 ±  0.0019\n",
      "    f1          :  0.9727 ±  0.0044\n",
      "    roc_auc     :  0.9986 ±  0.0013\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    6.16 MB\n",
      "    Training Time     : 0.18s\n",
      "    CV Time (total)   : 1.15s\n",
      "    Prediction Latency:  16.658 ms/sample\n",
      "\n",
      "RandomForest_medium\n",
      "-------------------\n",
      "  Configuration: RandomForest: n_estimators=100, min_samples_split=4, min_samples_leaf=2\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9558 ±  0.0078\n",
      "    precision   :  0.9282 ±  0.0098\n",
      "    recall      :  0.9880 ±  0.0075\n",
      "    f1          :  0.9572 ±  0.0075\n",
      "    roc_auc     :  0.9964 ±  0.0022\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :   10.49 MB\n",
      "    Training Time     : 0.30s\n",
      "    CV Time (total)   : 2.15s\n",
      "    Prediction Latency:  18.266 ms/sample\n",
      "\n",
      "RandomForest_complex\n",
      "--------------------\n",
      "  Configuration: RandomForest: n_estimators=150, class_weight='balanced'\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9725 ±  0.0054\n",
      "    precision   :  0.9502 ±  0.0091\n",
      "    recall      :  0.9972 ±  0.0022\n",
      "    f1          :  0.9731 ±  0.0052\n",
      "    roc_auc     :  0.9990 ±  0.0011\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :   18.48 MB\n",
      "    Training Time     : 0.53s\n",
      "    CV Time (total)   : 3.55s\n",
      "    Prediction Latency:  29.082 ms/sample\n",
      "\n",
      "GB_simple\n",
      "---------\n",
      "  Configuration: GradientBoosting: n_estimators=50, lr=0.1, max_depth=3\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7037 ±  0.0204\n",
      "    precision   :  0.7050 ±  0.0236\n",
      "    recall      :  0.7014 ±  0.0267\n",
      "    f1          :  0.7029 ±  0.0207\n",
      "    roc_auc     :  0.7732 ±  0.0200\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.07 MB\n",
      "    Training Time     : 0.38s\n",
      "    CV Time (total)   : 1.11s\n",
      "    Prediction Latency:   0.569 ms/sample\n",
      "\n",
      "GB_medium\n",
      "---------\n",
      "  Configuration: GradientBoosting: n_estimators=100, lr=0.05, subsample=0.8\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7062 ±  0.0228\n",
      "    precision   :  0.7038 ±  0.0233\n",
      "    recall      :  0.7123 ±  0.0291\n",
      "    f1          :  0.7079 ±  0.0236\n",
      "    roc_auc     :  0.7758 ±  0.0213\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.13 MB\n",
      "    Training Time     : 0.64s\n",
      "    CV Time (total)   : 2.05s\n",
      "    Prediction Latency:   0.688 ms/sample\n",
      "\n",
      "GB_complex\n",
      "----------\n",
      "  Configuration: GradientBoosting: n_estimators=150, lr=0.03, max_depth=4, subsample=0.8\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7351 ±  0.0191\n",
      "    precision   :  0.7293 ±  0.0223\n",
      "    recall      :  0.7487 ±  0.0250\n",
      "    f1          :  0.7386 ±  0.0189\n",
      "    roc_auc     :  0.8136 ±  0.0205\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.36 MB\n",
      "    Training Time     : 1.29s\n",
      "    CV Time (total)   : 3.86s\n",
      "    Prediction Latency:   0.605 ms/sample\n",
      "\n",
      "DecisionTree_simple\n",
      "-------------------\n",
      "  Configuration: DecisionTree: max_depth=3\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6714 ±  0.0191\n",
      "    precision   :  0.6845 ±  0.0173\n",
      "    recall      :  0.6355 ±  0.0348\n",
      "    f1          :  0.6588 ±  0.0244\n",
      "    roc_auc     :  0.7154 ±  0.0221\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.00 MB\n",
      "    Training Time     : 0.01s\n",
      "    CV Time (total)   : 0.06s\n",
      "    Prediction Latency:   0.533 ms/sample\n",
      "\n",
      "DecisionTree_medium\n",
      "-------------------\n",
      "  Configuration: DecisionTree: max_depth=6, min_samples_split=4\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6946 ±  0.0167\n",
      "    precision   :  0.6907 ±  0.0140\n",
      "    recall      :  0.7050 ±  0.0371\n",
      "    f1          :  0.6973 ±  0.0219\n",
      "    roc_auc     :  0.7602 ±  0.0152\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.01 MB\n",
      "    Training Time     : 0.02s\n",
      "    CV Time (total)   : 0.08s\n",
      "    Prediction Latency:   0.540 ms/sample\n",
      "\n",
      "DecisionTree_complex\n",
      "--------------------\n",
      "  Configuration: DecisionTree: max_depth=None, min_samples_split=2, min_samples_leaf=1\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9222 ±  0.0103\n",
      "    precision   :  0.8673 ±  0.0155\n",
      "    recall      :  0.9975 ±  0.0023\n",
      "    f1          :  0.9278 ±  0.0090\n",
      "    roc_auc     :  0.9222 ±  0.0103\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.12 MB\n",
      "    Training Time     : 0.03s\n",
      "    CV Time (total)   : 0.11s\n",
      "    Prediction Latency:   0.512 ms/sample\n",
      "\n",
      "LogReg_simple\n",
      "-------------\n",
      "  Configuration: LogReg: C=0.3, no class_weight, max_iter=1000\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6711 ±  0.0221\n",
      "    precision   :  0.6781 ±  0.0272\n",
      "    recall      :  0.6533 ±  0.0255\n",
      "    f1          :  0.6651 ±  0.0217\n",
      "    roc_auc     :  0.7220 ±  0.0227\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.00 MB\n",
      "    Training Time     : 0.35s\n",
      "    CV Time (total)   : 1.23s\n",
      "    Prediction Latency:   0.541 ms/sample\n",
      "\n",
      "LogReg_medium\n",
      "-------------\n",
      "  Configuration: LogReg: C=1.0, class_weight='balanced', max_iter=1500\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6708 ±  0.0182\n",
      "    precision   :  0.6775 ±  0.0208\n",
      "    recall      :  0.6527 ±  0.0250\n",
      "    f1          :  0.6647 ±  0.0194\n",
      "    roc_auc     :  0.7234 ±  0.0210\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.00 MB\n",
      "    Training Time     : 0.54s\n",
      "    CV Time (total)   : 1.92s\n",
      "    Prediction Latency:   0.532 ms/sample\n",
      "\n",
      "LogReg_complex\n",
      "--------------\n",
      "  Configuration: LogReg: C=3.0, class_weight='balanced', max_iter=2000\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6714 ±  0.0232\n",
      "    precision   :  0.6781 ±  0.0264\n",
      "    recall      :  0.6536 ±  0.0310\n",
      "    f1          :  0.6653 ±  0.0248\n",
      "    roc_auc     :  0.7252 ±  0.0216\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.00 MB\n",
      "    Training Time     : 0.68s\n",
      "    CV Time (total)   : 2.60s\n",
      "    Prediction Latency:   0.461 ms/sample\n",
      "\n",
      "SVC_simple\n",
      "----------\n",
      "  Configuration: SVC RBF: C=0.8, gamma='scale', no class_weight\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6425 ±  0.0266\n",
      "    precision   :  0.6510 ±  0.0251\n",
      "    recall      :  0.6130 ±  0.0400\n",
      "    f1          :  0.6312 ±  0.0317\n",
      "    roc_auc     :  0.7042 ±  0.0235\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.52 MB\n",
      "    Training Time     : 7.89s\n",
      "    CV Time (total)   : 28.50s\n",
      "    Prediction Latency:   0.891 ms/sample\n",
      "\n",
      "SVC_medium\n",
      "----------\n",
      "  Configuration: SVC RBF: C=2.0, gamma='scale', class_weight='balanced'\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6487 ±  0.0249\n",
      "    precision   :  0.6517 ±  0.0234\n",
      "    recall      :  0.6380 ±  0.0357\n",
      "    f1          :  0.6446 ±  0.0283\n",
      "    roc_auc     :  0.7051 ±  0.0237\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.51 MB\n",
      "    Training Time     : 17.23s\n",
      "    CV Time (total)   : 34.34s\n",
      "    Prediction Latency:   2.368 ms/sample\n",
      "\n",
      "SVC_complex\n",
      "-----------\n",
      "  Configuration: SVC RBF: C=4.0, gamma='scale', class_weight='balanced'\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6490 ±  0.0250\n",
      "    precision   :  0.6480 ±  0.0232\n",
      "    recall      :  0.6516 ±  0.0349\n",
      "    f1          :  0.6497 ±  0.0277\n",
      "    roc_auc     :  0.7056 ±  0.0239\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.51 MB\n",
      "    Training Time     : 10.36s\n",
      "    CV Time (total)   : 35.62s\n",
      "    Prediction Latency:   0.941 ms/sample\n",
      "\n",
      "MLP_simple\n",
      "----------\n",
      "  Configuration: MLP: hidden_layer_sizes=(32,), alpha=0.001, max_iter=400\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.5882 ±  0.0208\n",
      "    precision   :  0.5959 ±  0.0295\n",
      "    recall      :  0.5631 ±  0.0715\n",
      "    f1          :  0.5755 ±  0.0360\n",
      "    roc_auc     :  0.6193 ±  0.0278\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.02 MB\n",
      "    Training Time     : 0.24s\n",
      "    CV Time (total)   : 0.61s\n",
      "    Prediction Latency:   0.522 ms/sample\n",
      "\n",
      "MLP_medium\n",
      "----------\n",
      "  Configuration: MLP: hidden_layer_sizes=(64, 32), alpha=0.0005, max_iter=500\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6334 ±  0.0247\n",
      "    precision   :  0.6292 ±  0.0422\n",
      "    recall      :  0.6827 ±  0.1091\n",
      "    f1          :  0.6473 ±  0.0380\n",
      "    roc_auc     :  0.6806 ±  0.0283\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.07 MB\n",
      "    Training Time     : 1.32s\n",
      "    CV Time (total)   : 3.58s\n",
      "    Prediction Latency:   0.574 ms/sample\n",
      "\n",
      "MLP_complex\n",
      "-----------\n",
      "  Configuration: MLP: hidden_layer_sizes=(128, 64, 32), alpha=0.001, batch_size=64, max_iter=600\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6443 ±  0.0214\n",
      "    precision   :  0.6352 ±  0.0378\n",
      "    recall      :  0.7023 ±  0.1022\n",
      "    f1          :  0.6607 ±  0.0380\n",
      "    roc_auc     :  0.7059 ±  0.0269\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.28 MB\n",
      "    Training Time     : 3.60s\n",
      "    CV Time (total)   : 12.64s\n",
      "    Prediction Latency:   0.539 ms/sample\n",
      "\n",
      "XGB_simple\n",
      "----------\n",
      "  Configuration: XGBoost: n_estimators=50, lr=0.1, max_depth=4, subsample=0.8, colsample_bytree=0.8\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7243 ±  0.0206\n",
      "    precision   :  0.7194 ±  0.0238\n",
      "    recall      :  0.7365 ±  0.0253\n",
      "    f1          :  0.7276 ±  0.0201\n",
      "    roc_auc     :  0.8025 ±  0.0201\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.08 MB\n",
      "    Training Time     : 0.12s\n",
      "    CV Time (total)   : 0.21s\n",
      "    Prediction Latency:   0.927 ms/sample\n",
      "\n",
      "XGB_medium\n",
      "----------\n",
      "  Configuration: XGBoost: n_estimators=100, lr=0.05, max_depth=5, subsample=0.8, colsample_bytree=0.8\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7660 ±  0.0234\n",
      "    precision   :  0.7545 ±  0.0271\n",
      "    recall      :  0.7896 ±  0.0242\n",
      "    f1          :  0.7715 ±  0.0222\n",
      "    roc_auc     :  0.8485 ±  0.0194\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.23 MB\n",
      "    Training Time     : 0.09s\n",
      "    CV Time (total)   : 0.44s\n",
      "    Prediction Latency:   0.959 ms/sample\n",
      "\n",
      "XGB_complex\n",
      "-----------\n",
      "  Configuration: XGBoost: n_estimators=150, lr=0.03, max_depth=6, subsample=0.85, colsample_bytree=0.9\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.8002 ±  0.0197\n",
      "    precision   :  0.7793 ±  0.0242\n",
      "    recall      :  0.8389 ±  0.0203\n",
      "    f1          :  0.8077 ±  0.0177\n",
      "    roc_auc     :  0.8870 ±  0.0169\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.51 MB\n",
      "    Training Time     : 0.13s\n",
      "    CV Time (total)   : 0.78s\n",
      "    Prediction Latency:   0.903 ms/sample\n",
      "\n",
      "========================================================================================================================\n",
      "SUMMARY COMPARISON - ALL METRICS\n",
      "========================================================================================================================\n",
      "Model               Accuracy  Precision    Recall        F1   ROC-AUC  Size(MB)  Train(s)  Latency(ms)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "ExtraTrees_medium     0.9882     0.9795    0.9972    0.9883    0.9992     25.51      0.25       19.904\n",
      "    Config: ExtraTrees: n_estimators=100, min_samples_split=4, max_features='sqrt'\n",
      "ExtraTrees_simple     0.9882     0.9798    0.9969    0.9883    0.9992     12.96      0.13       17.438\n",
      "    Config: ExtraTrees: n_estimators=50, max_depth=None, max_features='sqrt'\n",
      "ExtraTrees_complex    0.9816     0.9671    0.9972    0.9819    0.9992     26.30      0.45       28.458\n",
      "    Config: ExtraTrees: n_estimators=150, max_features=None, min_samples_split=4\n",
      "RandomForest_complex    0.9725     0.9502    0.9972    0.9731    0.9990     18.48      0.53       29.082\n",
      "    Config: RandomForest: n_estimators=150, class_weight='balanced'\n",
      "RandomForest_simple    0.9720     0.9497    0.9969    0.9727    0.9986      6.16      0.18       16.658\n",
      "    Config: RandomForest: n_estimators=50, max_features='sqrt'\n",
      "RandomForest_medium    0.9558     0.9282    0.9880    0.9572    0.9964     10.49      0.30       18.266\n",
      "    Config: RandomForest: n_estimators=100, min_samples_split=4, min_samples_leaf=2\n",
      "DecisionTree_complex    0.9222     0.8673    0.9975    0.9278    0.9222      0.12      0.03        0.512\n",
      "    Config: DecisionTree: max_depth=None, min_samples_split=2, min_samples_leaf=1\n",
      "XGB_complex           0.8002     0.7793    0.8389    0.8077    0.8870      0.51      0.13        0.903\n",
      "    Config: XGBoost: n_estimators=150, lr=0.03, max_depth=6, subsample=0.85, colsample_bytree=0.9\n",
      "XGB_medium            0.7660     0.7545    0.7896    0.7715    0.8485      0.23      0.09        0.959\n",
      "    Config: XGBoost: n_estimators=100, lr=0.05, max_depth=5, subsample=0.8, colsample_bytree=0.8\n",
      "GB_complex            0.7351     0.7293    0.7487    0.7386    0.8136      0.36      1.29        0.605\n",
      "    Config: GradientBoosting: n_estimators=150, lr=0.03, max_depth=4, subsample=0.8\n",
      "XGB_simple            0.7243     0.7194    0.7365    0.7276    0.8025      0.08      0.12        0.927\n",
      "    Config: XGBoost: n_estimators=50, lr=0.1, max_depth=4, subsample=0.8, colsample_bytree=0.8\n",
      "GB_medium             0.7062     0.7038    0.7123    0.7079    0.7758      0.13      0.64        0.688\n",
      "    Config: GradientBoosting: n_estimators=100, lr=0.05, subsample=0.8\n",
      "GB_simple             0.7037     0.7050    0.7014    0.7029    0.7732      0.07      0.38        0.569\n",
      "    Config: GradientBoosting: n_estimators=50, lr=0.1, max_depth=3\n",
      "DecisionTree_medium    0.6946     0.6907    0.7050    0.6973    0.7602      0.01      0.02        0.540\n",
      "    Config: DecisionTree: max_depth=6, min_samples_split=4\n",
      "DecisionTree_simple    0.6714     0.6845    0.6355    0.6588    0.7154      0.00      0.01        0.533\n",
      "    Config: DecisionTree: max_depth=3\n",
      "LogReg_complex        0.6714     0.6781    0.6536    0.6653    0.7252      0.00      0.68        0.461\n",
      "    Config: LogReg: C=3.0, class_weight='balanced', max_iter=2000\n",
      "LogReg_simple         0.6711     0.6781    0.6533    0.6651    0.7220      0.00      0.35        0.541\n",
      "    Config: LogReg: C=0.3, no class_weight, max_iter=1000\n",
      "LogReg_medium         0.6708     0.6775    0.6527    0.6647    0.7234      0.00      0.54        0.532\n",
      "    Config: LogReg: C=1.0, class_weight='balanced', max_iter=1500\n",
      "SVC_complex           0.6490     0.6480    0.6516    0.6497    0.7056      0.51     10.36        0.941\n",
      "    Config: SVC RBF: C=4.0, gamma='scale', class_weight='balanced'\n",
      "SVC_medium            0.6487     0.6517    0.6380    0.6446    0.7051      0.51     17.23        2.368\n",
      "    Config: SVC RBF: C=2.0, gamma='scale', class_weight='balanced'\n",
      "MLP_complex           0.6443     0.6352    0.7023    0.6607    0.7059      0.28      3.60        0.539\n",
      "    Config: MLP: hidden_layer_sizes=(128, 64, 32), alpha=0.001, batch_size=64, max_iter=600\n",
      "SVC_simple            0.6425     0.6510    0.6130    0.6312    0.7042      0.52      7.89        0.891\n",
      "    Config: SVC RBF: C=0.8, gamma='scale', no class_weight\n",
      "MLP_medium            0.6334     0.6292    0.6827    0.6473    0.6806      0.07      1.32        0.574\n",
      "    Config: MLP: hidden_layer_sizes=(64, 32), alpha=0.0005, max_iter=500\n",
      "MLP_simple            0.5882     0.5959    0.5631    0.5755    0.6193      0.02      0.24        0.522\n",
      "    Config: MLP: hidden_layer_sizes=(32,), alpha=0.001, max_iter=400\n",
      "========================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "🔹 STEP 3/3: Evaluating on PCA feature set (12 components)\n",
      "\n",
      "=====================================\n",
      "=== Evaluating for PCA (balanced) ===\n",
      "=====================================\n",
      "\n",
      "\n",
      "ExtraTrees_simple\n",
      "-----------------\n",
      "  Configuration: ExtraTrees: n_estimators=50, max_depth=None, max_features='sqrt'\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9935 ±  0.0023\n",
      "    precision   :  0.9920 ±  0.0041\n",
      "    recall      :  0.9950 ±  0.0024\n",
      "    f1          :  0.9935 ±  0.0023\n",
      "    roc_auc     :  0.9983 ±  0.0015\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :   10.82 MB\n",
      "    Training Time     : 0.19s\n",
      "    CV Time (total)   : 0.90s\n",
      "    Prediction Latency:  19.444 ms/sample\n",
      "\n",
      "ExtraTrees_medium\n",
      "-----------------\n",
      "  Configuration: ExtraTrees: n_estimators=100, min_samples_split=4, max_features='sqrt'\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9939 ±  0.0027\n",
      "    precision   :  0.9928 ±  0.0046\n",
      "    recall      :  0.9950 ±  0.0024\n",
      "    f1          :  0.9939 ±  0.0026\n",
      "    roc_auc     :  0.9978 ±  0.0024\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :   21.52 MB\n",
      "    Training Time     : 0.26s\n",
      "    CV Time (total)   : 1.56s\n",
      "    Prediction Latency:  27.870 ms/sample\n",
      "\n",
      "ExtraTrees_complex\n",
      "------------------\n",
      "  Configuration: ExtraTrees: n_estimators=150, max_features=None, min_samples_split=4\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9890 ±  0.0035\n",
      "    precision   :  0.9832 ±  0.0055\n",
      "    recall      :  0.9950 ±  0.0024\n",
      "    f1          :  0.9891 ±  0.0035\n",
      "    roc_auc     :  0.9983 ±  0.0016\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :   21.86 MB\n",
      "    Training Time     : 0.56s\n",
      "    CV Time (total)   : 4.34s\n",
      "    Prediction Latency:  31.435 ms/sample\n",
      "\n",
      "RandomForest_simple\n",
      "-------------------\n",
      "  Configuration: RandomForest: n_estimators=50, max_features='sqrt'\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9789 ±  0.0028\n",
      "    precision   :  0.9636 ±  0.0043\n",
      "    recall      :  0.9953 ±  0.0025\n",
      "    f1          :  0.9792 ±  0.0028\n",
      "    roc_auc     :  0.9983 ±  0.0015\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    4.75 MB\n",
      "    Training Time     : 0.29s\n",
      "    CV Time (total)   : 2.14s\n",
      "    Prediction Latency:  23.000 ms/sample\n",
      "\n",
      "RandomForest_medium\n",
      "-------------------\n",
      "  Configuration: RandomForest: n_estimators=100, min_samples_split=4, min_samples_leaf=2\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9680 ±  0.0060\n",
      "    precision   :  0.9493 ±  0.0079\n",
      "    recall      :  0.9889 ±  0.0060\n",
      "    f1          :  0.9687 ±  0.0058\n",
      "    roc_auc     :  0.9970 ±  0.0020\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    8.65 MB\n",
      "    Training Time     : 0.58s\n",
      "    CV Time (total)   : 4.37s\n",
      "    Prediction Latency:  32.001 ms/sample\n",
      "\n",
      "RandomForest_complex\n",
      "--------------------\n",
      "  Configuration: RandomForest: n_estimators=150, class_weight='balanced'\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9797 ±  0.0058\n",
      "    precision   :  0.9655 ±  0.0094\n",
      "    recall      :  0.9950 ±  0.0024\n",
      "    f1          :  0.9800 ±  0.0056\n",
      "    roc_auc     :  0.9981 ±  0.0019\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :   14.23 MB\n",
      "    Training Time     : 0.85s\n",
      "    CV Time (total)   : 6.47s\n",
      "    Prediction Latency:  32.568 ms/sample\n",
      "\n",
      "GB_simple\n",
      "---------\n",
      "  Configuration: GradientBoosting: n_estimators=50, lr=0.1, max_depth=3\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7101 ±  0.0192\n",
      "    precision   :  0.7073 ±  0.0212\n",
      "    recall      :  0.7176 ±  0.0273\n",
      "    f1          :  0.7121 ±  0.0200\n",
      "    roc_auc     :  0.7952 ±  0.0172\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.07 MB\n",
      "    Training Time     : 1.42s\n",
      "    CV Time (total)   : 3.73s\n",
      "    Prediction Latency:   0.632 ms/sample\n",
      "\n",
      "GB_medium\n",
      "---------\n",
      "  Configuration: GradientBoosting: n_estimators=100, lr=0.05, subsample=0.8\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7173 ±  0.0177\n",
      "    precision   :  0.7117 ±  0.0203\n",
      "    recall      :  0.7315 ±  0.0224\n",
      "    f1          :  0.7212 ±  0.0172\n",
      "    roc_auc     :  0.7988 ±  0.0166\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.13 MB\n",
      "    Training Time     : 2.23s\n",
      "    CV Time (total)   : 6.50s\n",
      "    Prediction Latency:   0.784 ms/sample\n",
      "\n",
      "GB_complex\n",
      "----------\n",
      "  Configuration: GradientBoosting: n_estimators=150, lr=0.03, max_depth=4, subsample=0.8\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7522 ±  0.0208\n",
      "    precision   :  0.7446 ±  0.0232\n",
      "    recall      :  0.7688 ±  0.0257\n",
      "    f1          :  0.7562 ±  0.0203\n",
      "    roc_auc     :  0.8410 ±  0.0169\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.35 MB\n",
      "    Training Time     : 4.43s\n",
      "    CV Time (total)   : 12.27s\n",
      "    Prediction Latency:   0.788 ms/sample\n",
      "\n",
      "DecisionTree_simple\n",
      "-------------------\n",
      "  Configuration: DecisionTree: max_depth=3\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6400 ±  0.0221\n",
      "    precision   :  0.6453 ±  0.0529\n",
      "    recall      :  0.6675 ±  0.1314\n",
      "    f1          :  0.6447 ±  0.0403\n",
      "    roc_auc     :  0.6977 ±  0.0241\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.00 MB\n",
      "    Training Time     : 0.03s\n",
      "    CV Time (total)   : 0.11s\n",
      "    Prediction Latency:   0.474 ms/sample\n",
      "\n",
      "DecisionTree_medium\n",
      "-------------------\n",
      "  Configuration: DecisionTree: max_depth=6, min_samples_split=4\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7101 ±  0.0213\n",
      "    precision   :  0.7034 ±  0.0297\n",
      "    recall      :  0.7304 ±  0.0280\n",
      "    f1          :  0.7159 ±  0.0175\n",
      "    roc_auc     :  0.7746 ±  0.0221\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.01 MB\n",
      "    Training Time     : 0.08s\n",
      "    CV Time (total)   : 0.16s\n",
      "    Prediction Latency:   0.673 ms/sample\n",
      "\n",
      "DecisionTree_complex\n",
      "--------------------\n",
      "  Configuration: DecisionTree: max_depth=None, min_samples_split=2, min_samples_leaf=1\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9165 ±  0.0074\n",
      "    precision   :  0.8600 ±  0.0100\n",
      "    recall      :  0.9953 ±  0.0025\n",
      "    f1          :  0.9227 ±  0.0064\n",
      "    roc_auc     :  0.9165 ±  0.0074\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.09 MB\n",
      "    Training Time     : 0.13s\n",
      "    CV Time (total)   : 0.26s\n",
      "    Prediction Latency:   0.675 ms/sample\n",
      "\n",
      "LogReg_simple\n",
      "-------------\n",
      "  Configuration: LogReg: C=0.3, no class_weight, max_iter=1000\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6728 ±  0.0146\n",
      "    precision   :  0.6738 ±  0.0189\n",
      "    recall      :  0.6714 ±  0.0194\n",
      "    f1          :  0.6723 ±  0.0136\n",
      "    roc_auc     :  0.7297 ±  0.0169\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.00 MB\n",
      "    Training Time     : 0.01s\n",
      "    CV Time (total)   : 0.09s\n",
      "    Prediction Latency:   0.719 ms/sample\n",
      "\n",
      "LogReg_medium\n",
      "-------------\n",
      "  Configuration: LogReg: C=1.0, class_weight='balanced', max_iter=1500\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6726 ±  0.0145\n",
      "    precision   :  0.6737 ±  0.0189\n",
      "    recall      :  0.6711 ±  0.0193\n",
      "    f1          :  0.6721 ±  0.0135\n",
      "    roc_auc     :  0.7297 ±  0.0169\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.00 MB\n",
      "    Training Time     : 0.01s\n",
      "    CV Time (total)   : 0.09s\n",
      "    Prediction Latency:   0.985 ms/sample\n",
      "\n",
      "LogReg_complex\n",
      "--------------\n",
      "  Configuration: LogReg: C=3.0, class_weight='balanced', max_iter=2000\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6726 ±  0.0145\n",
      "    precision   :  0.6737 ±  0.0189\n",
      "    recall      :  0.6711 ±  0.0193\n",
      "    f1          :  0.6721 ±  0.0135\n",
      "    roc_auc     :  0.7297 ±  0.0169\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.00 MB\n",
      "    Training Time     : 0.03s\n",
      "    CV Time (total)   : 0.11s\n",
      "    Prediction Latency:   1.136 ms/sample\n",
      "\n",
      "SVC_simple\n",
      "----------\n",
      "  Configuration: SVC RBF: C=0.8, gamma='scale', no class_weight\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7134 ±  0.0171\n",
      "    precision   :  0.7101 ±  0.0211\n",
      "    recall      :  0.7226 ±  0.0221\n",
      "    f1          :  0.7160 ±  0.0163\n",
      "    roc_auc     :  0.7743 ±  0.0190\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.57 MB\n",
      "    Training Time     : 9.86s\n",
      "    CV Time (total)   : 32.43s\n",
      "    Prediction Latency:   0.998 ms/sample\n",
      "\n",
      "SVC_medium\n",
      "----------\n",
      "  Configuration: SVC RBF: C=2.0, gamma='scale', class_weight='balanced'\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7353 ±  0.0215\n",
      "    precision   :  0.7318 ±  0.0270\n",
      "    recall      :  0.7443 ±  0.0222\n",
      "    f1          :  0.7377 ±  0.0196\n",
      "    roc_auc     :  0.7961 ±  0.0212\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.55 MB\n",
      "    Training Time     : 10.32s\n",
      "    CV Time (total)   : 34.01s\n",
      "    Prediction Latency:   1.193 ms/sample\n",
      "\n",
      "SVC_complex\n",
      "-----------\n",
      "  Configuration: SVC RBF: C=4.0, gamma='scale', class_weight='balanced'\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7500 ±  0.0216\n",
      "    precision   :  0.7450 ±  0.0233\n",
      "    recall      :  0.7610 ±  0.0283\n",
      "    f1          :  0.7527 ±  0.0217\n",
      "    roc_auc     :  0.8167 ±  0.0210\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.54 MB\n",
      "    Training Time     : 10.72s\n",
      "    CV Time (total)   : 34.51s\n",
      "    Prediction Latency:   1.072 ms/sample\n",
      "\n",
      "MLP_simple\n",
      "----------\n",
      "  Configuration: MLP: hidden_layer_sizes=(32,), alpha=0.001, max_iter=400\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.6771 ±  0.0176\n",
      "    precision   :  0.6777 ±  0.0212\n",
      "    recall      :  0.6770 ±  0.0261\n",
      "    f1          :  0.6770 ±  0.0181\n",
      "    roc_auc     :  0.7314 ±  0.0155\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.02 MB\n",
      "    Training Time     : 1.89s\n",
      "    CV Time (total)   : 0.96s\n",
      "    Prediction Latency:   0.519 ms/sample\n",
      "\n",
      "MLP_medium\n",
      "----------\n",
      "  Configuration: MLP: hidden_layer_sizes=(64, 32), alpha=0.0005, max_iter=500\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.8495 ±  0.0650\n",
      "    precision   :  0.8122 ±  0.0561\n",
      "    recall      :  0.9085 ±  0.0735\n",
      "    f1          :  0.8574 ±  0.0628\n",
      "    roc_auc     :  0.8962 ±  0.0573\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.08 MB\n",
      "    Training Time     : 4.15s\n",
      "    CV Time (total)   : 12.72s\n",
      "    Prediction Latency:   0.654 ms/sample\n",
      "\n",
      "MLP_complex\n",
      "-----------\n",
      "  Configuration: MLP: hidden_layer_sizes=(128, 64, 32), alpha=0.001, batch_size=64, max_iter=600\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.9321 ±  0.0133\n",
      "    precision   :  0.8879 ±  0.0205\n",
      "    recall      :  0.9897 ±  0.0066\n",
      "    f1          :  0.9359 ±  0.0119\n",
      "    roc_auc     :  0.9576 ±  0.0086\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.29 MB\n",
      "    Training Time     : 9.30s\n",
      "    CV Time (total)   : 20.81s\n",
      "    Prediction Latency:   0.558 ms/sample\n",
      "\n",
      "XGB_simple\n",
      "----------\n",
      "  Configuration: XGBoost: n_estimators=50, lr=0.1, max_depth=4, subsample=0.8, colsample_bytree=0.8\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7401 ±  0.0170\n",
      "    precision   :  0.7334 ±  0.0201\n",
      "    recall      :  0.7554 ±  0.0215\n",
      "    f1          :  0.7440 ±  0.0162\n",
      "    roc_auc     :  0.8297 ±  0.0165\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.08 MB\n",
      "    Training Time     : 0.05s\n",
      "    CV Time (total)   : 0.25s\n",
      "    Prediction Latency:   0.969 ms/sample\n",
      "\n",
      "XGB_medium\n",
      "----------\n",
      "  Configuration: XGBoost: n_estimators=100, lr=0.05, max_depth=5, subsample=0.8, colsample_bytree=0.8\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.7923 ±  0.0160\n",
      "    precision   :  0.7745 ±  0.0188\n",
      "    recall      :  0.8256 ±  0.0278\n",
      "    f1          :  0.7989 ±  0.0161\n",
      "    roc_auc     :  0.8828 ±  0.0131\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.23 MB\n",
      "    Training Time     : 0.10s\n",
      "    CV Time (total)   : 0.67s\n",
      "    Prediction Latency:   0.973 ms/sample\n",
      "\n",
      "XGB_complex\n",
      "-----------\n",
      "  Configuration: XGBoost: n_estimators=150, lr=0.03, max_depth=6, subsample=0.85, colsample_bytree=0.9\n",
      "  Cross-Validation Metrics (10-fold):\n",
      "    accuracy    :  0.8406 ±  0.0146\n",
      "    precision   :  0.8151 ±  0.0185\n",
      "    recall      :  0.8818 ±  0.0215\n",
      "    f1          :  0.8469 ±  0.0138\n",
      "    roc_auc     :  0.9218 ±  0.0115\n",
      "\n",
      "  Model Characteristics:\n",
      "    Model Size        :    0.50 MB\n",
      "    Training Time     : 0.21s\n",
      "    CV Time (total)   : 1.36s\n",
      "    Prediction Latency:   1.091 ms/sample\n",
      "\n",
      "========================================================================================================================\n",
      "SUMMARY COMPARISON - ALL METRICS\n",
      "========================================================================================================================\n",
      "Model               Accuracy  Precision    Recall        F1   ROC-AUC  Size(MB)  Train(s)  Latency(ms)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "ExtraTrees_medium     0.9939     0.9928    0.9950    0.9939    0.9978     21.52      0.26       27.870\n",
      "    Config: ExtraTrees: n_estimators=100, min_samples_split=4, max_features='sqrt'\n",
      "ExtraTrees_simple     0.9935     0.9920    0.9950    0.9935    0.9983     10.82      0.19       19.444\n",
      "    Config: ExtraTrees: n_estimators=50, max_depth=None, max_features='sqrt'\n",
      "ExtraTrees_complex    0.9890     0.9832    0.9950    0.9891    0.9983     21.86      0.56       31.435\n",
      "    Config: ExtraTrees: n_estimators=150, max_features=None, min_samples_split=4\n",
      "RandomForest_complex    0.9797     0.9655    0.9950    0.9800    0.9981     14.23      0.85       32.568\n",
      "    Config: RandomForest: n_estimators=150, class_weight='balanced'\n",
      "RandomForest_simple    0.9789     0.9636    0.9953    0.9792    0.9983      4.75      0.29       23.000\n",
      "    Config: RandomForest: n_estimators=50, max_features='sqrt'\n",
      "RandomForest_medium    0.9680     0.9493    0.9889    0.9687    0.9970      8.65      0.58       32.001\n",
      "    Config: RandomForest: n_estimators=100, min_samples_split=4, min_samples_leaf=2\n",
      "MLP_complex           0.9321     0.8879    0.9897    0.9359    0.9576      0.29      9.30        0.558\n",
      "    Config: MLP: hidden_layer_sizes=(128, 64, 32), alpha=0.001, batch_size=64, max_iter=600\n",
      "DecisionTree_complex    0.9165     0.8600    0.9953    0.9227    0.9165      0.09      0.13        0.675\n",
      "    Config: DecisionTree: max_depth=None, min_samples_split=2, min_samples_leaf=1\n",
      "MLP_medium            0.8495     0.8122    0.9085    0.8574    0.8962      0.08      4.15        0.654\n",
      "    Config: MLP: hidden_layer_sizes=(64, 32), alpha=0.0005, max_iter=500\n",
      "XGB_complex           0.8406     0.8151    0.8818    0.8469    0.9218      0.50      0.21        1.091\n",
      "    Config: XGBoost: n_estimators=150, lr=0.03, max_depth=6, subsample=0.85, colsample_bytree=0.9\n",
      "XGB_medium            0.7923     0.7745    0.8256    0.7989    0.8828      0.23      0.10        0.973\n",
      "    Config: XGBoost: n_estimators=100, lr=0.05, max_depth=5, subsample=0.8, colsample_bytree=0.8\n",
      "GB_complex            0.7522     0.7446    0.7688    0.7562    0.8410      0.35      4.43        0.788\n",
      "    Config: GradientBoosting: n_estimators=150, lr=0.03, max_depth=4, subsample=0.8\n",
      "SVC_complex           0.7500     0.7450    0.7610    0.7527    0.8167      0.54     10.72        1.072\n",
      "    Config: SVC RBF: C=4.0, gamma='scale', class_weight='balanced'\n",
      "XGB_simple            0.7401     0.7334    0.7554    0.7440    0.8297      0.08      0.05        0.969\n",
      "    Config: XGBoost: n_estimators=50, lr=0.1, max_depth=4, subsample=0.8, colsample_bytree=0.8\n",
      "SVC_medium            0.7353     0.7318    0.7443    0.7377    0.7961      0.55     10.32        1.193\n",
      "    Config: SVC RBF: C=2.0, gamma='scale', class_weight='balanced'\n",
      "GB_medium             0.7173     0.7117    0.7315    0.7212    0.7988      0.13      2.23        0.784\n",
      "    Config: GradientBoosting: n_estimators=100, lr=0.05, subsample=0.8\n",
      "SVC_simple            0.7134     0.7101    0.7226    0.7160    0.7743      0.57      9.86        0.998\n",
      "    Config: SVC RBF: C=0.8, gamma='scale', no class_weight\n",
      "GB_simple             0.7101     0.7073    0.7176    0.7121    0.7952      0.07      1.42        0.632\n",
      "    Config: GradientBoosting: n_estimators=50, lr=0.1, max_depth=3\n",
      "DecisionTree_medium    0.7101     0.7034    0.7304    0.7159    0.7746      0.01      0.08        0.673\n",
      "    Config: DecisionTree: max_depth=6, min_samples_split=4\n",
      "MLP_simple            0.6771     0.6777    0.6770    0.6770    0.7314      0.02      1.89        0.519\n",
      "    Config: MLP: hidden_layer_sizes=(32,), alpha=0.001, max_iter=400\n",
      "LogReg_simple         0.6728     0.6738    0.6714    0.6723    0.7297      0.00      0.01        0.719\n",
      "    Config: LogReg: C=0.3, no class_weight, max_iter=1000\n",
      "LogReg_medium         0.6726     0.6737    0.6711    0.6721    0.7297      0.00      0.01        0.985\n",
      "    Config: LogReg: C=1.0, class_weight='balanced', max_iter=1500\n",
      "LogReg_complex        0.6726     0.6737    0.6711    0.6721    0.7297      0.00      0.03        1.136\n",
      "    Config: LogReg: C=3.0, class_weight='balanced', max_iter=2000\n",
      "DecisionTree_simple    0.6400     0.6453    0.6675    0.6447    0.6977      0.00      0.03        0.474\n",
      "    Config: DecisionTree: max_depth=3\n",
      "========================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "========================================================================================================================\n",
      "🏆 FINAL COMPARISON ACROSS ALL FEATURE SETS\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Optional libraries\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "except ImportError:\n",
    "    XGBClassifier = None\n",
    "\n",
    "\n",
    "def _nice_time(seconds: float) -> str:\n",
    "    \"\"\"Format seconds into a human-readable string.\"\"\"\n",
    "    if seconds < 60:\n",
    "        return f\"{seconds:.2f}s\"\n",
    "    m, s = divmod(seconds, 60)\n",
    "    if m < 60:\n",
    "        return f\"{int(m)}m {s:.1f}s\"\n",
    "    h, m = divmod(m, 60)\n",
    "    return f\"{int(h)}h {int(m)}m\"\n",
    "\n",
    "\n",
    "def evaluate_models(X_df, y_series, desc=\"\"):\n",
    "    \"\"\"\n",
    "    Evaluate multiple ML models with cross-validation and performance metrics.\n",
    "    Returns detailed comparison including accuracy, size, and latency.\n",
    "    Now uses multiple configurations per model (simple → medium → complex).\n",
    "    \"\"\"\n",
    "    banner = f\"=== Evaluating for {desc} ===\"\n",
    "    print(\"\\n\" + \"=\" * len(banner))\n",
    "    print(banner)\n",
    "    print(\"=\" * len(banner) + \"\\n\")\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Model configurations: (name, estimator_instance, config_description)\n",
    "    # Simple → Medium → Complex for each base model\n",
    "    # ------------------------------------------------------------------\n",
    "    model_specs = []\n",
    "\n",
    "    # ExtraTrees\n",
    "    model_specs.append((\n",
    "        \"ExtraTrees_simple\",\n",
    "        ExtraTreesClassifier(\n",
    "            n_estimators=50,\n",
    "            max_depth=None,\n",
    "            max_features=\"sqrt\",\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"ExtraTrees: n_estimators=50, max_depth=None, max_features='sqrt'\"\n",
    "    ))\n",
    "    model_specs.append((\n",
    "        \"ExtraTrees_medium\",\n",
    "        ExtraTreesClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=None,\n",
    "            max_features=\"sqrt\",\n",
    "            min_samples_split=4,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"ExtraTrees: n_estimators=100, min_samples_split=4, max_features='sqrt'\"\n",
    "    ))\n",
    "    model_specs.append((\n",
    "        \"ExtraTrees_complex\",\n",
    "        ExtraTreesClassifier(\n",
    "            n_estimators=150,\n",
    "            max_depth=None,\n",
    "            max_features=None,\n",
    "            min_samples_split=4,\n",
    "            min_samples_leaf=1,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"ExtraTrees: n_estimators=150, max_features=None, min_samples_split=4\"\n",
    "    ))\n",
    "\n",
    "    # RandomForest\n",
    "    model_specs.append((\n",
    "        \"RandomForest_simple\",\n",
    "        RandomForestClassifier(\n",
    "            n_estimators=50,\n",
    "            max_depth=None,\n",
    "            max_features=\"sqrt\",\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"RandomForest: n_estimators=50, max_features='sqrt'\"\n",
    "    ))\n",
    "    model_specs.append((\n",
    "        \"RandomForest_medium\",\n",
    "        RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=None,\n",
    "            min_samples_split=4,\n",
    "            min_samples_leaf=2,\n",
    "            max_features=\"sqrt\",\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"RandomForest: n_estimators=100, min_samples_split=4, min_samples_leaf=2\"\n",
    "    ))\n",
    "    model_specs.append((\n",
    "        \"RandomForest_complex\",\n",
    "        RandomForestClassifier(\n",
    "            n_estimators=150,\n",
    "            max_depth=None,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            max_features=\"sqrt\",\n",
    "            n_jobs=-1,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"RandomForest: n_estimators=150, class_weight='balanced'\"\n",
    "    ))\n",
    "\n",
    "    # GradientBoosting\n",
    "    model_specs.append((\n",
    "        \"GB_simple\",\n",
    "        GradientBoostingClassifier(\n",
    "            n_estimators=50,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=3,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"GradientBoosting: n_estimators=50, lr=0.1, max_depth=3\"\n",
    "    ))\n",
    "    model_specs.append((\n",
    "        \"GB_medium\",\n",
    "        GradientBoostingClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=3,\n",
    "            subsample=0.8,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"GradientBoosting: n_estimators=100, lr=0.05, subsample=0.8\"\n",
    "    ))\n",
    "    model_specs.append((\n",
    "        \"GB_complex\",\n",
    "        GradientBoostingClassifier(\n",
    "            n_estimators=150,\n",
    "            learning_rate=0.03,\n",
    "            max_depth=4,\n",
    "            subsample=0.8,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"GradientBoosting: n_estimators=150, lr=0.03, max_depth=4, subsample=0.8\"\n",
    "    ))\n",
    "\n",
    "    # DecisionTree\n",
    "    model_specs.append((\n",
    "        \"DecisionTree_simple\",\n",
    "        DecisionTreeClassifier(\n",
    "            max_depth=3,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"DecisionTree: max_depth=3\"\n",
    "    ))\n",
    "    model_specs.append((\n",
    "        \"DecisionTree_medium\",\n",
    "        DecisionTreeClassifier(\n",
    "            max_depth=6,\n",
    "            min_samples_split=4,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"DecisionTree: max_depth=6, min_samples_split=4\"\n",
    "    ))\n",
    "    model_specs.append((\n",
    "        \"DecisionTree_complex\",\n",
    "        DecisionTreeClassifier(\n",
    "            max_depth=None,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"DecisionTree: max_depth=None, min_samples_split=2, min_samples_leaf=1\"\n",
    "    ))\n",
    "\n",
    "    # LogisticRegression\n",
    "    model_specs.append((\n",
    "        \"LogReg_simple\",\n",
    "        LogisticRegression(\n",
    "            penalty=\"l2\",\n",
    "            C=0.3,\n",
    "            solver=\"lbfgs\",\n",
    "            max_iter=1000,\n",
    "            class_weight=None,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"LogReg: C=0.3, no class_weight, max_iter=1000\"\n",
    "    ))\n",
    "    model_specs.append((\n",
    "        \"LogReg_medium\",\n",
    "        LogisticRegression(\n",
    "            penalty=\"l2\",\n",
    "            C=1.0,\n",
    "            solver=\"lbfgs\",\n",
    "            max_iter=1500,\n",
    "            class_weight=\"balanced\",\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"LogReg: C=1.0, class_weight='balanced', max_iter=1500\"\n",
    "    ))\n",
    "    model_specs.append((\n",
    "        \"LogReg_complex\",\n",
    "        LogisticRegression(\n",
    "            penalty=\"l2\",\n",
    "            C=3.0,\n",
    "            solver=\"lbfgs\",\n",
    "            max_iter=2000,\n",
    "            class_weight=\"balanced\",\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"LogReg: C=3.0, class_weight='balanced', max_iter=2000\"\n",
    "    ))\n",
    "\n",
    "    # SVC (RBF)\n",
    "    model_specs.append((\n",
    "        \"SVC_simple\",\n",
    "        SVC(\n",
    "            kernel=\"rbf\",\n",
    "            C=0.8,\n",
    "            gamma=\"scale\",\n",
    "            probability=True,\n",
    "            class_weight=None,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"SVC RBF: C=0.8, gamma='scale', no class_weight\"\n",
    "    ))\n",
    "    model_specs.append((\n",
    "        \"SVC_medium\",\n",
    "        SVC(\n",
    "            kernel=\"rbf\",\n",
    "            C=2.0,\n",
    "            gamma=\"scale\",\n",
    "            probability=True,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"SVC RBF: C=2.0, gamma='scale', class_weight='balanced'\"\n",
    "    ))\n",
    "    model_specs.append((\n",
    "        \"SVC_complex\",\n",
    "        SVC(\n",
    "            kernel=\"rbf\",\n",
    "            C=4.0,\n",
    "            gamma=\"scale\",\n",
    "            probability=True,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"SVC RBF: C=4.0, gamma='scale', class_weight='balanced'\"\n",
    "    ))\n",
    "\n",
    "    # MLPs (simple → deep)\n",
    "    model_specs.append((\n",
    "        \"MLP_simple\",\n",
    "        MLPClassifier(\n",
    "            hidden_layer_sizes=(32,),\n",
    "            activation=\"relu\",\n",
    "            solver=\"adam\",\n",
    "            alpha=0.001,\n",
    "            learning_rate=\"adaptive\",\n",
    "            learning_rate_init=0.001,\n",
    "            max_iter=400,\n",
    "            early_stopping=True,\n",
    "            validation_fraction=0.1,\n",
    "            n_iter_no_change=15,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"MLP: hidden_layer_sizes=(32,), alpha=0.001, max_iter=400\"\n",
    "    ))\n",
    "    model_specs.append((\n",
    "        \"MLP_medium\",\n",
    "        MLPClassifier(\n",
    "            hidden_layer_sizes=(64, 32),\n",
    "            activation=\"relu\",\n",
    "            solver=\"adam\",\n",
    "            alpha=0.0005,\n",
    "            learning_rate=\"adaptive\",\n",
    "            learning_rate_init=0.001,\n",
    "            max_iter=500,\n",
    "            early_stopping=True,\n",
    "            validation_fraction=0.1,\n",
    "            n_iter_no_change=20,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"MLP: hidden_layer_sizes=(64, 32), alpha=0.0005, max_iter=500\"\n",
    "    ))\n",
    "    model_specs.append((\n",
    "        \"MLP_complex\",\n",
    "        MLPClassifier(\n",
    "            hidden_layer_sizes=(128, 64, 32),\n",
    "            activation=\"relu\",\n",
    "            solver=\"adam\",\n",
    "            alpha=0.001,\n",
    "            learning_rate=\"adaptive\",\n",
    "            learning_rate_init=0.001,\n",
    "            max_iter=600,\n",
    "            early_stopping=True,\n",
    "            validation_fraction=0.1,\n",
    "            n_iter_no_change=25,\n",
    "            batch_size=64,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        \"MLP: hidden_layer_sizes=(128, 64, 32), alpha=0.001, batch_size=64, max_iter=600\"\n",
    "    ))\n",
    "\n",
    "    # XGBoost (if available)\n",
    "    if XGBClassifier is not None:\n",
    "        model_specs.append((\n",
    "            \"XGB_simple\",\n",
    "            XGBClassifier(\n",
    "                n_estimators=50,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=4,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                reg_lambda=1.0,\n",
    "                objective=\"binary:logistic\",\n",
    "                eval_metric=\"logloss\",\n",
    "                use_label_encoder=False,\n",
    "                random_state=42,\n",
    "                verbosity=0,\n",
    "            ),\n",
    "            \"XGBoost: n_estimators=50, lr=0.1, max_depth=4, subsample=0.8, colsample_bytree=0.8\"\n",
    "        ))\n",
    "        model_specs.append((\n",
    "            \"XGB_medium\",\n",
    "            XGBClassifier(\n",
    "                n_estimators=100,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=5,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                reg_lambda=1.0,\n",
    "                objective=\"binary:logistic\",\n",
    "                eval_metric=\"logloss\",\n",
    "                use_label_encoder=False,\n",
    "                random_state=42,\n",
    "                verbosity=0,\n",
    "            ),\n",
    "            \"XGBoost: n_estimators=100, lr=0.05, max_depth=5, subsample=0.8, colsample_bytree=0.8\"\n",
    "        ))\n",
    "        model_specs.append((\n",
    "            \"XGB_complex\",\n",
    "            XGBClassifier(\n",
    "                n_estimators=150,\n",
    "                learning_rate=0.03,\n",
    "                max_depth=6,\n",
    "                subsample=0.85,\n",
    "                colsample_bytree=0.9,\n",
    "                reg_lambda=1.0,\n",
    "                objective=\"binary:logistic\",\n",
    "                eval_metric=\"logloss\",\n",
    "                use_label_encoder=False,\n",
    "                random_state=42,\n",
    "                verbosity=0,\n",
    "            ),\n",
    "            \"XGBoost: n_estimators=150, lr=0.03, max_depth=6, subsample=0.85, colsample_bytree=0.9\"\n",
    "        ))\n",
    "\n",
    "    results = {}\n",
    "    scoring = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Main evaluation loop\n",
    "    # ------------------------------------------------------------------\n",
    "    for name, model, config_desc in model_specs:\n",
    "        print(f\"\\n{name}\")\n",
    "        print(\"-\" * len(name))\n",
    "        print(f\"  Configuration: {config_desc}\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # Cross-validation performance\n",
    "        # -----------------------------\n",
    "        cv_start = time.time()\n",
    "        cv_res = cross_validate(\n",
    "            model,\n",
    "            X_df,\n",
    "            y_series,\n",
    "            cv=skf,\n",
    "            scoring=scoring,\n",
    "            return_train_score=False,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        cv_time = time.time() - cv_start\n",
    "\n",
    "        summary = {\n",
    "            metric: (\n",
    "                np.mean(cv_res[f\"test_{metric}\"]),\n",
    "                np.std(cv_res[f\"test_{metric}\"]),\n",
    "            )\n",
    "            for metric in scoring\n",
    "        }\n",
    "\n",
    "        # -----------------------------\n",
    "        # Train on full dataset\n",
    "        # -----------------------------\n",
    "        train_start = time.time()\n",
    "        model.fit(X_df, y_series)\n",
    "        train_time = time.time() - train_start\n",
    "\n",
    "        # Model size\n",
    "        model_bytes = len(pickle.dumps(model))\n",
    "        model_size_mb = model_bytes / (1024 * 1024)\n",
    "\n",
    "        # Prediction latency (single-sample)\n",
    "        sample = X_df.iloc[:1]\n",
    "        latencies = []\n",
    "        for _ in range(100):\n",
    "            start = time.time()\n",
    "            _ = model.predict(sample)\n",
    "            latencies.append((time.time() - start) * 1000.0)  # ms\n",
    "        avg_latency_ms = np.mean(latencies)\n",
    "\n",
    "        # Store results (including config description)\n",
    "        results[name] = {\n",
    "            \"metrics\": summary,\n",
    "            \"model_size_mb\": model_size_mb,\n",
    "            \"train_time_s\": train_time,\n",
    "            \"cv_time_s\": cv_time,\n",
    "            \"latency_ms\": avg_latency_ms,\n",
    "            \"config\": config_desc,\n",
    "        }\n",
    "\n",
    "        # -----------------------------\n",
    "        # Per-model printout\n",
    "        # -----------------------------\n",
    "        print(\"  Cross-Validation Metrics (10-fold):\")\n",
    "        for metric, (m, s) in summary.items():\n",
    "            print(f\"    {metric:12s}: {m:7.4f} ± {s:7.4f}\")\n",
    "\n",
    "        print(\"\\n  Model Characteristics:\")\n",
    "        print(f\"    Model Size        : {model_size_mb:7.2f} MB\")\n",
    "        print(f\"    Training Time     : {_nice_time(train_time)}\")\n",
    "        print(f\"    CV Time (total)   : {_nice_time(cv_time)}\")\n",
    "        print(f\"    Prediction Latency: {avg_latency_ms:7.3f} ms/sample\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Summary comparison table with ALL metrics, sorted by accuracy\n",
    "    # ------------------------------------------------------------------\n",
    "    print(\"\\n\" + \"=\" * 120)\n",
    "    print(\"SUMMARY COMPARISON - ALL METRICS\")\n",
    "    print(\"=\" * 120)\n",
    "    header = (\n",
    "        f\"{'Model':<18}\"\n",
    "        f\"{'Accuracy':>10}\"\n",
    "        f\"{'Precision':>11}\"\n",
    "        f\"{'Recall':>10}\"\n",
    "        f\"{'F1':>10}\"\n",
    "        f\"{'ROC-AUC':>10}\"\n",
    "        f\"{'Size(MB)':>10}\"\n",
    "        f\"{'Train(s)':>10}\"\n",
    "        f\"{'Latency(ms)':>13}\"\n",
    "    )\n",
    "    print(header)\n",
    "    print(\"-\" * 120)\n",
    "\n",
    "    sorted_items = sorted(\n",
    "        results.items(),\n",
    "        key=lambda kv: kv[1][\"metrics\"][\"accuracy\"][0],\n",
    "        reverse=True,\n",
    "    )\n",
    "\n",
    "    for name, res in sorted_items:\n",
    "        acc = res[\"metrics\"][\"accuracy\"][0]\n",
    "        prec = res[\"metrics\"][\"precision\"][0]\n",
    "        rec = res[\"metrics\"][\"recall\"][0]\n",
    "        f1 = res[\"metrics\"][\"f1\"][0]\n",
    "        roc = res[\"metrics\"][\"roc_auc\"][0]\n",
    "        size = res[\"model_size_mb\"]\n",
    "        train_t = res[\"train_time_s\"]\n",
    "        lat = res[\"latency_ms\"]\n",
    "\n",
    "        print(\n",
    "            f\"{name:<18}\"\n",
    "            f\"{acc:10.4f}\"\n",
    "            f\"{prec:11.4f}\"\n",
    "            f\"{rec:10.4f}\"\n",
    "            f\"{f1:10.4f}\"\n",
    "            f\"{roc:10.4f}\"\n",
    "            f\"{size:10.2f}\"\n",
    "            f\"{train_t:10.2f}\"\n",
    "            f\"{lat:13.3f}\"\n",
    "        )\n",
    "        # Also print config on the next line for clarity\n",
    "        print(f\"    Config: {res['config']}\")\n",
    "\n",
    "    print(\"=\" * 120 + \"\\n\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Example usage with your three feature sets\n",
    "# ----------------------------------------------------------------------\n",
    "print(\"\\n\\n🔹 STEP 1/3: Evaluating on ORIGINAL feature set (all features)\")\n",
    "res_orig = evaluate_models(X_orig_bal, y_orig_bal, desc=\"Original (balanced)\")\n",
    "\n",
    "print(\"\\n\\n🔹 STEP 2/3: Evaluating on mRMR feature set (10 selected features)\")\n",
    "res_mrmr = evaluate_models(X_mrmr_bal, y_mrmr_bal, desc=\"mRMR (balanced)\")\n",
    "\n",
    "print(\"\\n\\n🔹 STEP 3/3: Evaluating on PCA feature set (12 components)\")\n",
    "res_pca = evaluate_models(X_pca_bal, y_pca_bal, desc=\"PCA (balanced)\")\n",
    "\n",
    "print(\"\\n\\n\" + \"=\" * 120)\n",
    "print(\"🏆 FINAL COMPARISON ACROSS ALL FEATURE SETS\")\n",
    "print(\"=\" * 120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efa6dd",
   "metadata": {
    "id": "c3efa6dd",
    "papermill": {
     "duration": 0.005623,
     "end_time": "2025-10-24T16:00:23.636133",
     "exception": false,
     "start_time": "2025-10-24T16:00:23.630510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 8. Hyperparameter tuning for simple ExtraTrees on PCA features\n",
    "Based on the comparison results, we'll tune a simple ExtraTrees configuration on PCA features using RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3889b1",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning: Simple ExtraTrees on PCA Features\n",
    "\n",
    "After comparing all models and configurations, we now focus on tuning a **simple ExtraTrees** model with **PCA features** for optimal performance.\n",
    "\n",
    "**Why this specific configuration?**\n",
    "- **ExtraTrees_simple**: Fast, efficient baseline with good generalization\n",
    "- **PCA features**: Decorrelated 12-component representation reduces multicollinearity\n",
    "- **Configuration**: `n_estimators=50`, `max_features='sqrt'`, `max_depth=None`\n",
    "\n",
    "**Tuning process:**\n",
    "1. Define search space around the simple configuration\n",
    "2. Use **RandomizedSearchCV** to sample 20 parameter combinations\n",
    "3. Optimize for **ROC-AUC** (ideal for imbalanced medical data)\n",
    "4. Use 5-fold cross-validation to evaluate each combination\n",
    "\n",
    "**The final model:**\n",
    "```python\n",
    "best_et = rscv.best_estimator_\n",
    "best_et.fit(X_pca_bal, y_pca_bal)\n",
    "```\n",
    "- Extracts the best hyperparameters found\n",
    "- Retrains on the full balanced PCA dataset\n",
    "- Ready for final evaluation and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f1d9b6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T16:00:23.648434Z",
     "iopub.status.busy": "2025-10-24T16:00:23.648204Z",
     "iopub.status.idle": "2025-10-24T16:00:56.567765Z",
     "shell.execute_reply": "2025-10-24T16:00:56.567006Z"
    },
    "id": "2f1d9b6b",
    "outputId": "dadf08e1-5a9b-4682-bec9-c93dd8f52036",
    "papermill": {
     "duration": 32.927049,
     "end_time": "2025-10-24T16:00:56.568848",
     "exception": false,
     "start_time": "2025-10-24T16:00:23.641799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning simple ExtraTrees on PCA features...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "\n",
      "Best parameters found: {'n_estimators': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 30, 'class_weight': None}\n",
      "Best ROC-AUC score: 0.9993\n",
      "\n",
      "Final model trained and ready for evaluation.\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for simple ExtraTrees on PCA features\n",
    "# Starting from the simple configuration: n_estimators=50, max_features='sqrt'\n",
    "\n",
    "param_grid_et = {\n",
    "    'n_estimators': [50, 100, 150],           # Keep it simple, centered around 50\n",
    "    'min_samples_split': [2, 4, 6],           # Regularization\n",
    "    'min_samples_leaf': [1, 2, 3],            # Leaf node control\n",
    "    'max_features': ['sqrt', 'log2', None],   # Feature subset strategy\n",
    "    'max_depth': [None, 20, 30],              # Tree depth\n",
    "    'class_weight': [None, 'balanced']        # Handle any residual imbalance\n",
    "}\n",
    "\n",
    "et_simple = ExtraTreesClassifier(random_state=42, n_jobs=-1)\n",
    "rscv = RandomizedSearchCV(\n",
    "    et_simple, \n",
    "    param_grid_et, \n",
    "    n_iter=20, \n",
    "    cv=5, \n",
    "    scoring='roc_auc', \n",
    "    n_jobs=-1, \n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Tuning simple ExtraTrees on PCA features...\")\n",
    "rscv.fit(X_pca_bal, y_pca_bal)\n",
    "print(\"\\nBest parameters found:\", rscv.best_params_)\n",
    "print(f\"Best ROC-AUC score: {rscv.best_score_:.4f}\")\n",
    "\n",
    "# Fit final model with best params\n",
    "best_et = rscv.best_estimator_\n",
    "best_et.fit(X_pca_bal, y_pca_bal)\n",
    "print(\"\\nFinal model trained and ready for evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afdedaa",
   "metadata": {
    "id": "4afdedaa",
    "papermill": {
     "duration": 0.006301,
     "end_time": "2025-10-24T16:00:56.581980",
     "exception": false,
     "start_time": "2025-10-24T16:00:56.575679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 9. Evaluate final model on held-out 30% test (split before if you want true test)\n",
    "We'll split PCA balanced into train/test 70/30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d182c301",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T16:00:56.595224Z",
     "iopub.status.busy": "2025-10-24T16:00:56.595002Z",
     "iopub.status.idle": "2025-10-24T16:00:57.335690Z",
     "shell.execute_reply": "2025-10-24T16:00:57.334918Z"
    },
    "id": "d182c301",
    "outputId": "d6b13108-5b61-424e-9c55-c386612d3e2c",
    "papermill": {
     "duration": 0.748922,
     "end_time": "2025-10-24T16:00:57.337092",
     "exception": false,
     "start_time": "2025-10-24T16:00:56.588170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics for ExtraTrees (PCA):\n",
      "Accuracy: 0.9856281872971719\n",
      "Precision: 0.9789569990850869\n",
      "Recall: 0.9925788497217068\n",
      "F1: 0.9857208659603869\n",
      "ROC_AUC: 0.9961196290800423\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pca_bal, y_pca_bal, test_size=0.3, stratify=y_pca_bal, random_state=42)\n",
    "best_et.fit(X_train, y_train)\n",
    "y_pred = best_et.predict(X_test)\n",
    "y_proba = best_et.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"Test metrics for ExtraTrees (PCA):\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1:\", f1_score(y_test, y_pred))\n",
    "print(\"ROC_AUC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.title(\"Confusion matrix (ExtraTrees, PCA)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e451eb27",
   "metadata": {
    "id": "e451eb27",
    "papermill": {
     "duration": 0.043452,
     "end_time": "2025-10-24T16:08:19.475453",
     "exception": false,
     "start_time": "2025-10-24T16:08:19.432001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 12. Save model if desired\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fadfe1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T16:08:19.560678Z",
     "iopub.status.busy": "2025-10-24T16:08:19.560024Z",
     "iopub.status.idle": "2025-10-24T16:08:19.608471Z",
     "shell.execute_reply": "2025-10-24T16:08:19.607644Z"
    },
    "id": "6fadfe1d",
    "outputId": "6b53fd55-e79c-47c0-ef97-d695aea22318",
    "papermill": {
     "duration": 0.092639,
     "end_time": "2025-10-24T16:08:19.609620",
     "exception": false,
     "start_time": "2025-10-24T16:08:19.516981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: scaler.pkl, pca.pkl, best_extratrees_pca.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Save the fitted scaler, PCA, and final ExtraTrees model\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(pca, \"pca.pkl\")\n",
    "joblib.dump(best_et, \"best_extratrees_pca.pkl\")\n",
    "\n",
    "print(\"Saved: scaler.pkl, pca.pkl, best_extratrees_pca.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20fbde74",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Download the model file to your local machine (Google Colab)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[32m      3\u001b[39m files.download(\u001b[33m'\u001b[39m\u001b[33mbest_extratrees_pca.pkl\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# Download the model file to your local machine (Google Colab)\n",
    "from google.colab import files\n",
    "files.download('best_extratrees_pca.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e122de39",
   "metadata": {
    "id": "e122de39"
   },
   "source": [
    "## Quick end‑to‑end summary (what we did and why)\n",
    "\n",
    "- **Cleaned the Framingham dataset** so that all models receive numeric, NaN‑free inputs.  \n",
    "- **Engineered clinically meaningful features** (pulse pressure, MAP, age×BP) to better capture cardiovascular risk.  \n",
    "- **Created three feature views**: all features, an **mRMR‑selected subset**, and a **12‑component PCA representation**.  \n",
    "- **Balanced the dataset** via oversampling to handle the rare CHD cases fairly.  \n",
    "- **Trained and compared multiple model configurations** (simple/medium/complex) across 8 different model families on each feature view with 10-fold cross‑validation, measuring not just accuracy but also model size, training time, and prediction latency.\n",
    "- **Tuned an ExtraTrees model** on the PCA features using RandomizedSearchCV for stronger performance.  \n",
    "- **Evaluated the tuned model on a held‑out test set** to estimate real‑world generalization.  \n",
    "- **Explained the model's behavior with SHAP and LIME** to understand both global patterns and individual predictions.  \n",
    "- **Saved the final model** so it can be reused without retraining.\n",
    "\n",
    "You can now experiment with:\n",
    "\n",
    "- Changing which features go into mRMR or PCA.  \n",
    "- Adding more model configurations (e.g., ultra-simple for edge deployment, or ultra-complex for maximum accuracy).\n",
    "- Tuning other high-performing model families identified in the comparison (e.g., XGBoost, SVC).  \n",
    "- Applying SHAP/LIME to alternative models for comparison.\n",
    "- Adjusting the complexity levels to find the sweet spot between performance and deployment constraints.\n",
    "\n",
    "**Key insight**: The comprehensive comparison across models, configurations, and feature sets helps you make informed tradeoffs between accuracy, interpretability, model size, and prediction speed—critical considerations for deploying ML in healthcare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2102888,
     "sourceId": 3493583,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 714.849649,
   "end_time": "2025-10-24T16:08:22.268661",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-24T15:56:27.419012",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
